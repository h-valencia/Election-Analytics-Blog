---
title: Final Prediction
author: Hannah Valencia
date: '2022-11-04'
slug: []
categories: []
tags: []
summary: "Over the past nine weeks, we have explored a multitude of variables that may impact election outcomes in an attempt to forecast the 2022 midterm election. We have learned about economic forces, polling, expert predictions, incumbency, advertising, campaigning, and more to find if they hold any predictive power, and how together in a model they may foreshadow what is to come in the results next week. In this blog, I will create a final prediction model for the House of Representatives and share its results, with the intention of reflecting on it after the election." 
---

*This blog is part of a series related to Gov 1347: Election Analytics, a course at [Harvard University](https://www.harvard.edu/) taught by Professor [Ryan D. Enos](http://ryandenos.com/)*.

*Over the past nine weeks, we have explored a multitude of variables that may impact election outcomes in an attempt to forecast the 2022 midterm election. We have learned about economic forces, polling, expert predictions, incumbency, advertising, campaigning, and more to find if they hold any predictive power, and how together in a model they may foreshadow what is to come in the results next week. In this blog, I will create a final prediction model for the House of Representatives and share its results, with the intention of reflecting on it after the election.*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# load libraries

library(tidyverse)
library(usmap)
library(plotly)
library(rmapshaper)
library(sf)
library(haven)
library(stringr)
library(sjlabelled)
library(usdata)
library(ggpubr)
library(stargazer)

```

Since this class first convened in the beginning of September, we have time and time again been reminded of the shortcomings of election forecasting. Elections are fickle and there is no way to know for certain how voters will vote on election day. The experts oftentimes cannot predict what will happen, if an election will be toss-up or a landslide. There are shocks that no one sees coming, costs of voting that may be unanticipated, various biases with polling, and ever-changing political opinions that result from all sorts of issues and news. While these unknowns make forecasting very difficult, we have gained the tools over the last nine weeks that give us a good foundation to create predictions of our own for the House of Representatives midterm election.

In building my model, the first choice I had was what to use as my dependent variable and the level on which to predict on. For my dependent variable, I decided to run models for both Democratic seat share and Democratic vote share to see the results of both and how they may unveil different stories about the election. I also created variables putting the vote share and seat share in terms of the incumbent party to see how incumbents perform without paying specific attention to their party affiliation, but I decided that this approach would complicate interpreting results. While we spent multiple weeks working with district-level data and forecasting each of the 435 districts, in the end I have decided to predict vote share and seat share on the national level. We have more data for these variables and do not have to rely upon things like pooling, that may produce greater margins for error. Given the insufficient district-level data, a pooled model would have allowed us to take data from neighboring, similar districts and count it as its own. My national model was heading in the right direction in terms of improving predictability and the lack of district data led me to this decision. 

In the first week of class, we looked at the fundamentals of election forecasting models, with predictors like the president's party. We learned about the phenomenon that takes place in most midterms where the president's party tends to lose seats. Following these basics, in week two we looked at how Real Disposable Income (RDI) on its own does a decent job of predicting elections. We also took a look at a slew of other economic variables, such as the Consumer Price Index (CPI), GDP growth rate, unemployment, and more. Despite the overlap between the government and the economy, most of these variables proved to be insignificant and poor predictors for the House elections. The one economic variable I will be using in my final model the unemployment rate, as it is typically a decent indicator of the health of the economy. In addition to using it on its own, I have also decided to interact it with the president's party. The most important topics to voters vary based on their political party affiliation, and Republicans are known to weigh economic factors more heavily. Therefore, an interaction term between party and unemployment rate can provide us with more significant results than the two can separately on their own.

We continued on from the fundamentals and economic variables onto polling, looking at the generic ballot as well as district-level polls. 

```{r}

# reading in data

distdata <- read_csv("fulldata.csv") # master df by district
natldata <- read_csv("data2.csv", skip = 1) # master df 
popvote_df <- read_csv("popvote_df.csv", skip = 1, col_types = cols(...1 = col_skip(), ...2 = col_skip()))
rdi_df <- read_csv("RDI_quarterly.csv") %>% select(!`...1`)
qtnatl <- read_csv("data1.csv") %>% select(!c(`...1`, `...2`))
gallup_approval <- read_csv("Gallup approval.csv")
```


```{r}

# recreating Professor Enos's graph from week 1 illustrating the relationship between percent change RDI and the seat change in the president's party

# adding seat share and president party to the data frame with national-level data

a <- distdata %>%
  distinct(year, president_party)

b <- popvote_df %>%
  select(year, R_seats, D_seats, Other_seats)

natldata1 <- left_join(natldata, a, by = c("year" = "year"))
natldata1 <- left_join(natldata1, b, by = c("year" = "year")) %>% select(!`...1`)

# lagging the seats to create a variable that has the seat change for the President's party

c <- b %>%
  mutate(year = year + 2) %>%
  rename(R_seats_previous = R_seats,
         D_seats_previous = D_seats,
         Other_seats_previous = Other_seats)

natldata1 <- left_join(natldata1, c, by = c("year" = "year"))

natldata1 <- natldata1 %>%
  mutate(pres_party_seat_change = ifelse(president_party == "R", (R_seats - R_seats_previous), (D_seats - D_seats_previous)))

# creating a variable for the percent change in RDI for each election year
# coded as the percent change in RDI from Q3 of the election year (aka Q7) from the RDI from Q3 of the previous year

rdi_df1 <- rdi_df %>%
  mutate(election_year = 1:nrow(rdi_df) %/% 8,
         election_year = lag(election_year, default = 0)) %>%
  group_by(election_year) %>%
  filter(election_year != 31) %>%
  mutate(pct_rdi_election = (DSPIC_qt[quarter_cycle == 7] - DSPIC_qt[quarter_cycle == 3])/DSPIC_qt[quarter_cycle == 3]*100)

rdi_df1 <- rdi_df1 %>%
  distinct(year, pct_rdi_election)

natldata1 <- left_join(natldata1, rdi_df1, by = c("year" = "year"))

# For some reason the graph I produce is different than that of Professor Enos's, likely due to slight differences in the way we coded the variables.
# Even though I will not include the recreated graph in this post, I have the same new variables that I can possibly incorporate into a model or graph later on.

# x <- natldata1 %>% select(year, pres_party_seat_change, pct_rdi_election)

# natldata1 %>%
#   ggplot(aes(x = pct_rdi_election, y = pres_party_seat_change, label = year)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = TRUE, alpha = .25,size = 2) +
#   labs(title = "Descriptive Relationship Between RDI Change and \n President's Party Seat Change in House",
#        x = "Percent Change in RDI",
#        y = "President's Party Seat Change",
#        caption = "RDI = Real Disposable Income, Midterm years in black, \n change from Q3 of election year - 1 year") +
#   scale_color_manual(values=c("darkgrey","black")) +
#   scale_y_continuous(breaks = seq(-60, 40, by = 10)) +
#   theme(legend.position = "none")
```

```{r}

d <- distdata %>%
  select(year, gen_avg_dem, gen_avg_rep) %>%
  distinct(year, gen_avg_dem, gen_avg_rep)

e <- qtnatl %>%
  distinct(year, R_majorvote_pct, D_majorvote_pct)

natldata1 <- left_join(natldata1, d, by = c("year" = "year"))
natldata1 <- left_join(natldata1, e, by = c("year" = "year"))

# creating two new dependent variables in case I want to try them out
# vote share and seat share for the president's party rather than just the democratic and republican ones

natldata1 <- natldata1 %>%
  mutate(pres_party_vote_pct = ifelse(president_party == "D", D_majorvote_pct, R_majorvote_pct),
         pres_party_seat_share = ifelse(president_party == "D", DemSeatShare, RepSeatShare))

# creating a variable for if the year is a midterm election year

natldata2 <- natldata1
natldata2$midterm <- seq_len(nrow(natldata2)) %% 2L + 1L
natldata2$midterm[natldata2$midterm == 2] <- 0

# adding presidential approval ratings for each year from Gallup Analytics

natldata2 <- left_join(natldata2, gallup_approval, by = c("year" = "year"))

# adding lagged vote share
f <- natldata2 %>%
  mutate(year = year + 2,
         DemVS_prev = D_majorvote_pct) %>%
  select(year, DemVS_prev)

# googled the seat share for 1958 to fill in for 1960's lag

natldata2 <- left_join(natldata2, f, by = c("year" = "year"))
natldata2$DemVS_prev[natldata2$year == 1960] <- 56.0

# adding lagged seat share to get same effect as the lagged vote share but for the seat share model
g <- natldata2 %>%
  mutate(year = year + 2,
         DemSeatShare_prev = DemSeatShare) %>%
  select(year, DemSeatShare_prev)

# googled the seat share for 1958 to fill in for 1960's lag

natldata2 <- left_join(natldata2, g, by = c("year" = "year"))
natldata2$DemSeatShare_prev[natldata2$year == 1960] <- (283/435)

# changing the format of the seat share variable to match that of vote share (ex. 56 instead of 0.56)
natldata2 <- natldata2 %>%
  mutate(DemSeatShare = DemSeatShare * 100)


```

```{r, results='asis'}

# modelling Democratic vote share

fit1a <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem)
#summary(fit1a) 

fit1b <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev)
#summary(fit1b)

fit1c <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev + president_party)
#summary(fit1c)

fit1d <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev + president_party + approval_rating)
#summary(fit1d)

fit1e <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev + president_party + approval_rating + midterm*president_party)
#summary(fit1e)

fit1f <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev + president_party + approval_rating + midterm*president_party + unrate + unrate*president_party)
# summary(fit1f)

stargazer(fit1a, fit1b, fit1c, fit1d, fit1e, fit1f, type = "html", covariate.labels = c("Generic Ballot Support - D", "Lag House Dem VS", "President Party - R", "President Approval Rating", "Midterm Year", "Unemployment Rate", "President Party - R * Midterm Year", "President Party - R * Unemployment", "Constant"))

```


```{r, results = 'asis'}
# modelling Democratic seat share

fit2a <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem)
#summary(fit2a) 

fit2b <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev)
#summary(fit2b)

fit2c <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev + president_party)
#summary(fit2c)

fit2d <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev + president_party + approval_rating)
#summary(fit2d)

fit2e <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev + president_party + approval_rating + midterm*president_party)
#summary(fit2e)

fit2f <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev + president_party + approval_rating + midterm*president_party + unrate + unrate*president_party)
#summary(fit2f)

stargazer(fit2a, fit2b, fit2c, fit2d, fit2e, fit2f, type = "html", covariate.labels = c("Generic Ballot Support - D", "Lag House Dem Seat Share", "President Party - R", "President Approval Rating", "Midterm Year", "Unemployment Rate", "President Party - R * Midterm Year", "President Party - R * Unemployment", "Constant"))

```


```{r, results = 'asis'}

# trying new models only using midterm years

midtermdata <- natldata2 %>%
  filter(midterm == 1)

fit3a <- lm(data = midtermdata, D_majorvote_pct ~ gen_avg_dem)
#summary(fit3a) 

fit3b <- lm(data = midtermdata, D_majorvote_pct ~ gen_avg_dem + president_party)
#summary(fit3b)

fit3c <- lm(data = midtermdata, D_majorvote_pct ~ gen_avg_dem + president_party + DemVS_prev)
#summary(fit3c)

stargazer(fit3a, fit3b, fit3c, type = "html", covariate.labels = c("Generic Ballot Support - D", "President Party - R", "Lag House Dem VS"))


# seat share model for only midterm years

fit4a <- lm(data = midtermdata, DemSeatShare ~ gen_avg_dem)
#summary(fit4a) 

fit4b <- lm(data = midtermdata, DemSeatShare ~ gen_avg_dem + president_party)
#summary(fit4b)

fit4c <- lm(data = midtermdata, DemSeatShare ~ gen_avg_dem + president_party + DemSeatShare_prev)
#summary(fit4c)

stargazer(fit4a, fit4b, fit4c, type = "html", covariate.labels = c("Generic Ballot Support - D", "President Party - R", "Lag House Dem Seat Share"))

```

```{r}

# creating a dataframe with the 2022 independent variables data

data2022 <- data.frame(gen_avg_dem = 45.5, # fivethirtyeight
                       DemVS_prev = natldata2$D_majorvote_pct[natldata2$year == 2020],
                       DemSeatShare_prev = natldata2$DemSeatShare[natldata2$year == 2020],
                       president_party = "D",
                       approval_rating = 0.40, # gallup
                       midterm = 1,
                       unrate = 3.7) # bls

# predicting the 2022 election using each model

predict(fit1f, data2022, interval = "confidence") # Democratic Vote Share using all years
predict(fit2f, data2022, interval = "confidence") # Democratic Seat Share using all years
predict(fit3c, data2022, interval = "confidence") # Democratic Vote Share using midterm years
predict(fit4c, data2022, interval = "confidence") # Democratic Seat Share using midterm years
```

```{r}
# in sample testing
# creating empty columns for the predictions of each of my four final models

natldata2$prediction1 <- NA
natldata2$prediction2 <- NA
natldata2$prediction3 <- NA
natldata2$prediction4 <- NA

# creating a for loop that fills in the data frame with the predictions for each model for every year

for (i in 1960:2020){
  x <- natldata2 %>%
    filter(year == i) %>%
    select(gen_avg_dem,DemVS_prev,DemSeatShare_prev, president_party, approval_rating, midterm, unrate)
  
  natldata2$prediction1[natldata2$year == i] <- predict(fit1f, x, interval = "confidence")[1]
  natldata2$prediction2[natldata2$year == i] <- predict(fit2f, x, interval = "confidence")[1] 
  natldata2$prediction3[natldata2$year == i] <- predict(fit3c, x, interval = "confidence")[1] 
  natldata2$prediction4[natldata2$year == i] <- predict(fit4c, x, interval = "confidence")[1] 
}

```

```{r}

# Dem VS all years plot

natldata2 %>%
  ggplot(aes(x = prediction1, y = D_majorvote_pct, label = year)) +
  geom_point() +
  geom_abline(y = x, color = "red") +
  geom_text(hjust=0, vjust=0, size = 3) +
  labs(x = "Precited Democratic Vote Share (all years)",
       y = "Actual Democratic Vote Share",
       title = "Actual vs. Predicted Democratic Vote Share (all years)") +
  stat_cor(method="pearson")

```

```{r}
# Dem Seat Share all years plot

natldata2 %>%
  ggplot(aes(x = prediction2, y = DemSeatShare, label = year)) +
  geom_point() +
  geom_abline(y = x, color = "red") +
  geom_text(hjust=0, vjust=0, size = 3) +
  labs(x = "Precited Democratic Seat Share (all years)",
       y = "Actual Democratic Seat Share",
       title = "Actual vs. Predicted Democratic Seat Share (all years)") +
  stat_cor(method="pearson")
```

```{r}

# Dem VS midterm years plot

natldata2 %>%
  filter(midterm == 1) %>%
  ggplot(aes(x = prediction3, y = D_majorvote_pct, label = year)) +
  geom_point() +
  geom_abline(y = x, color = "red") +
  geom_text(hjust=0, vjust=0, size = 3) +
  labs(x = "Precited Democratic Vote Share (midterm years)",
       y = "Actual Democratic Vote Share",
       title = "Actual vs. Predicted Democratic Vote Share (midterm years)") +
  stat_cor(method="pearson")

```

```{r}

# Dem Seat Share midterm years plot

natldata2 %>%
  filter(midterm == 1) %>%
  ggplot(aes(x = prediction4, y = D_majorvote_pct, label = year)) +
  geom_point() +
  geom_abline(y = x, color = "red") +
  geom_text(hjust=0, vjust=0, size = 3) +
  labs(x = "Precited Democratic Seat Share (midterm years)",
       y = "Actual Democratic Seat Share",
       title = "Actual vs. Predicted Democratic Seat Share (midterm years)") +
  stat_cor(method="pearson")

```


































