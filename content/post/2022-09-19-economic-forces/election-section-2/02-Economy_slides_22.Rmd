---
title: "Fundamentals I: Economy"
subtitle: "Gov 1347: Election Analytics"
author: Kiara Hernandez
date: \today
institute: Harvard University
fontsize: 10pt
output:
 beamer_presentation:
    keep_tex: true
    theme: metropolis
    latex_engine: pdflatex
    slide_level: 2
    highlight: zenburn
    incremental: false
header-includes:
  \setbeamercolor{frametitle}{bg=purple}
  \hypersetup{colorlinks,citecolor=orange,filecolor=red,linkcolor=brown,urlcolor=blue}
---
<!-- 
to make handout, add 
classoption: "handout"
to header
-->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse); library(car)
```

## Today's goal

**Can we predict midterm election outcomes using *only* the state of the economy?**

1. **Describing how the economy relates to elections**

    * Bivariate correlation between $X$ and $Y$ ($r_{XY}$)

2. **How to make a prediction by fitting a model to your data:**

    * Linear regression of $Y$ on $X$

3. **How to evaluate your model:**

    * In-sample model fit
    * Out-of-sample model testing
    * Out-of-sample extrapolation

4. **How to improve your model:**

    * Measure for a single independent variable
    * Multiple independent variables

# Before we start, quick recap of code for national map

## left_join by district and state
```{r, include=TRUE, eval=FALSE}
# example from Blog 01
R_2014 <- h %>%
  filter(raceYear == 2014) %>% #State == "New Jersey") %>% 
  select(raceYear, State, district_num, RepVotesMajorPercent, DemVotesMajorPercent) %>%
  # summarize party vote share by district
  group_by(district_num, State) %>%
  summarise(Rep_votes_pct = RepVotesMajorPercent) %>%
  # rename district and state variable to match shapefile
  rename(DISTRICT = district_num, STATENAME = State)

# merge
cd114$DISTRICT <- as.numeric(cd114$DISTRICT)
cd114 <- cd114 %>% left_join(R_2014, by=c("DISTRICT", "STATENAME"))
```

## Use package 'rmapshaper' to plot - rmapshaper::ms_simplify()

```{r, include=TRUE, eval=FALSE}
# plot with simplify
districts_simp <- rmapshaper::ms_simplify(cd114, keep = 0.01)

```

## Add a layer to your ggplot to set geographic parameters: coord_sf()

```{r, include=TRUE, eval=FALSE, fig.width=5, fig.height=3, out.width = '60%', fig.align='center'}
ggplot() + 
  geom_sf(data=districts_simp,aes(fill=Rep_votes_pct),
          inherit.aes=FALSE,alpha=0.9) + 
  scale_fill_gradient(low = "white", high = "black", limits=c(0,90)) +
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +  
  theme_void() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

```

```{r, include = FALSE, echo=FALSE, eval=TRUE}
# mapping districts
# required packages 
require(tidyverse)
require(ggplot2)
require(sf)
# load geographic data
get_congress_map <- function(cong=114) {
  tmp_file <- tempfile()
  tmp_dir  <- tempdir()
  zp <- sprintf("https://cdmaps.polisci.ucla.edu/shp/districts114.zip",cong)
  download.file(zp, tmp_file)
  unzip(zipfile = tmp_file, exdir = tmp_dir)
  fpath <- paste(tmp_dir, sprintf("districtShapes/districts114.shp",cong), sep = "/")
  st_read(fpath)
}

# load 114th congress
cd114 <- get_congress_map(114)

# vote data
house_party_vote_share_by_district_1948_2020 <- read_csv("~/Dropbox/ElectionAnalytics_Midterms/Lab sessions/Intro/Section data/house party vote share by district 1948-2020.csv")
h <- house_party_vote_share_by_district_1948_2020


R_2014 <- h %>%
  filter(raceYear == 2014) %>% #State == "New Jersey") %>% 
  select(raceYear, State, district_num, district_id, RepVotesMajorPercent, DemVotesMajorPercent) %>%
  # summarize party vote share by district
  group_by(district_num, State, district_id) %>%
  summarise(Rep_votes_pct = RepVotesMajorPercent) %>%
  # rename district variable name to match shapefile
  rename(DISTRICT = district_num, STATENAME = State)

# merge
cd114$DISTRICT <- as.numeric(cd114$DISTRICT)
cd114 <- cd114 %>% left_join(R_2014, by=c("DISTRICT", "STATENAME"))
head(cd114$Rep_votes_pct)

# plot with simplify
districts_simp <- rmapshaper::ms_simplify(cd114, keep = 0.01)

ggplot() + 
  geom_sf(data=districts_simp,aes(fill=Rep_votes_pct),
          inherit.aes=FALSE,alpha=0.9) + 
  #geom_sf_label(data=districts_simp, aes(label = district_id),
                #label.size  = NA, alpha = 0.5,
                #size = 3) +
  geom_sf_text(data=districts_simp, aes(label = district_id), 
               check_overlap = TRUE) +
  scale_fill_gradient(low = "white", high = "black", limits=c(0,90)) +
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +  
  theme_void() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

```

```{r, include=FALSE, eval=TRUE, fig.width=5, fig.height=3, out.width = '60%', fig.align='center'}
ggplot() + 
  geom_sf(data=districts_simp,aes(fill=Rep_votes_pct),
          inherit.aes=FALSE,alpha=0.9) + 
  scale_fill_gradient(low = "white", high = "black", limits=c(0,90)) +
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +  
  theme_void() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

```
# Describing how the economy relates to elections

## Bivariate correlation of economy and PV
STARTING HERE
```{r, include = FALSE, message=FALSE}

# load house and seat share by year
library(readr)
popvote_df <- read_csv('house_popvote_seats.csv') 
                                                   
# load GDP data by quarter
economy_df <- read_csv('GDP_quarterly.csv')

# merge
dat <- left_join(economy_df, popvote_df, by = 'year')

# drop NAs (only election years)
dat <- dat %>%
  drop_na()

# new df
dat2 <- dat %>% 
    select('year', 'winner_party', 'H_incumbent_party', 'H_incumbent_party_majorvote_pct', 
           'quarter_cycle', 'GDP_growth_pct') %>%
    filter(quarter_cycle == 8)  
```

A \textbf{scatterplot} visualizes bivariate correlation between some 
$X$ (independent variable or IV) and $Y$ (dependent variable or DV). \pause 
```{r, echo=FALSE, eval=TRUE, fig.width=5, fig.height=3, out.width = '60%', fig.align='center'}
dat2 %>%
  ggplot(aes(x=GDP_growth_pct, y=H_incumbent_party_majorvote_pct,
             label=year)) + 
    geom_text() +
    geom_hline(yintercept=50, lty=2) +
    geom_vline(xintercept=0.01, lty=2) + # median
    xlab("Q8-Q7 GDP growth") +
    ylab("Incumbent party PV") +
    theme_bw() +
    theme(
      axis.text = element_text(size = 10)
    )
```

\pause \textbf{Bivariate correlation} is formally measured from -1 to 1 as: $r_{XY} = \frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i-\bar{y})^2}}$. \pause

<!-- Q: can anyone guess what the correlation here is? -->
```{r, eval=FALSE}
cor(dat2$GDP_growth_pct, dat2$H_incumbent_party_majorvote_pct)
```
\pause 
```{r, echo=FALSE, eval=TRUE}
cor(dat2$GDP_growth_pct, dat2$H_incumbent_party_majorvote_pct)
```

## Bivariate correlation of economy and PV

```{r, include = FALSE, message=FALSE}


##################################


# now do the same for RDI
rdi_df <- read_csv('RDI_quarterly.csv')
popvote_df <- read_csv('house_popvote_seats.csv')

# merge    
data <- left_join(rdi_df, popvote_df, by = 'year')

# drop NAs (only election years)
data <- data %>%
  drop_na()

# new df
data2 <- data %>% 
    select('year', 'winner_party', 'H_incumbent_party', 'H_incumbent_party_majorvote_pct', 
           'quarter_cycle', 'DSPIC_change_pct') %>%
    filter(quarter_cycle == 8) 
        
# plot 
data2 %>%
  ggplot(aes(x=DSPIC_change_pct, y=H_incumbent_party_majorvote_pct,
             label=year)) + 
    geom_text() +
    geom_hline(yintercept=50, lty=2) +
    geom_vline(xintercept=0.01, lty=2) + # median
    xlab("Q8-Q7 pct change RDI") +
    ylab("Incumbent party PV") +
    theme_bw() +
    theme(
      axis.text = element_text(size = 10)
    )
```


A \textbf{scatterplot} visualizes bivariate correlation between some 
$X$ (independent variable or IV) and $Y$ (dependent variable or DV). 
```{r, echo=FALSE, eval=TRUE, fig.width=5, fig.height=3, out.width = '60%', fig.align='center'}
data2 %>%
  ggplot(aes(x=DSPIC_change_pct, y=H_incumbent_party_majorvote_pct,
             label=year)) + 
    geom_text() +
    geom_hline(yintercept=50, lty=2) +
    geom_vline(xintercept=0.01, lty=2) + # median
    xlab("Q8-Q7 pct change RDI") +
    ylab("Incumbent party PV") +
    theme_bw() +
    theme(
      axis.text = element_text(size = 10)
    )
```

\textbf{Bivariate correlation} is formally measured from -1 to 1 as: $r_{XY} = \frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i-\bar{y})^2}}$.

```{r, eval=FALSE}
cor(data2$DSPIC_change_pct, data2$H_incumbent_party_majorvote_pct)
```
\pause 
```{r, echo=FALSE, eval=TRUE}
cor(data2$DSPIC_change_pct, data2$H_incumbent_party_majorvote_pct)
```

## Summary of bivariate correlation

Strong bivariate correlation means $X$ probably predicts $Y$ well.

\begin{figure}
\includegraphics[width=0.5\textwidth, height=0.5\textheight]{correlation.png}
\end{figure}  \pause

But, correlation can't tell us what the underlying model is to generate $Y$ from $X$.

# How to make a prediction by fitting a model to your data

## How to make a prediction {.build}

Given some variable (DV) $Y$ that you wish to predict: \pause

\textbf{STEP 1.} Specify a model in the form of a function $Y = f(X)$ for some proposed $X$, the IV. \pause

\textbf{STEP 2.} Estimate the parameters of that function from a sample $(x_1,y_1),\ldots,(x_n,y_n)$ observed of the variables. \pause

\textbf{STEP 3.} Determine whether parameters are "good". \pause

\textbf{STEP 4.} Obtain a new observation of the IV, $X_{new}$. \pause

\textbf{STEP 5.} Predict its DV $Y_{new}$ value as $\widehat{Y}_{new} = f(X_{new})$. \pause

\textbf{STEP 6.} Calculate uncertainty about estimate $\widehat{Y}_{new}$.

## How to make a prediction using linear regression {.build}

Given some variable (DV) $Y$ that you wish to predict:

\textbf{STEP 1.} \only<1>{\textcolor{gray}{Specify a model in the form of a function $Y = f(X)$ for some proposed $X$, the IV.}}\only<2->{Specify a model in the form $Y = \underbrace{A}_{intercept} + \underbrace{B}_{slope}X$.}

\textbf{STEP 2.} \only<-2>{\textcolor{gray}{Estimate the parameters of that function from a sample $(x_1,y_1),\ldots,(x_n,y_n)$ observed of the variables.}}\only<3->{Calculate estimates $\widehat{A}$ and $\widehat{B}$, the "best guesses" at the slopes and intercepts, from a sample $(x_1,y_1),\ldots,(x_n,y_n)$ observed of the variables.}

\textbf{STEP 3.} \only<-3>{\textcolor{gray}{Determine whether parameters are "good".}}\only<4->{Check in-sample model fit and perform out-of-sample testing.}

\textbf{STEP 4.} \only<-4>{\textcolor{gray}{Obtain a new observation of the IV, $X_{new}$.}}\only<5->{Obtain a new observation of the IV, $X_{new}$.}

\textbf{STEP 5.} \only<-5>{\textcolor{gray}{Predict its DV $Y_{new}$ value as $\widehat{Y}_{new} = f(X_{new})$.}}\only<6->{Predict its DV $Y_{new}$ value as $\widehat{Y}_{new} = \widehat{A} + \widehat{B}X_{new}$.}

\textbf{STEP 6.} \only<-6>{\textcolor{gray}{Calculate uncertainty about estimate $\widehat{Y}_{new}$.}}\only<7->{Calculate a \textbf{prediction interval} for $\widehat{Y}_{new}$ as $\widehat{Y}_{new} \pm 1.96^{*} \times \text{se}^{**}(\widehat{Y}_{new})$.}

\tiny \only<8->{$^{*}$If we truly believe our model and we additionally assume errors between all $Y$ and predicted $\hat{Y}$ are normally distributed, scaling the standard deviation by $1.96$ ensures that our predictive interval will contain the true $Y_{new}$ $95\%$ of the time.} 

\tiny \only<8->{$^{**}$Standard Error.}
\normalsize

## Economy and PV: Fitting a model (STEP 1 \& 2) {.build}

For now let's use just a single IV for two models: (1) Q8-Q7 GDP growth and (2) Q8-Q7 percent change RDI. \pause We can fit a \underline{l}inear regression \underline{m}odel using `lm()`:

We can fit this \underline{l}inear regression \underline{m}odel using `lm()`:

```{r, echo=TRUE}
lm_econ <- lm(H_incumbent_party_majorvote_pct ~ GDP_growth_pct, 
              data = dat2)
# # lm_rdi <- lm(H_incumbent_party_majorvote_pct ~ DSPIC_change_pct, 
#              data = data2)

```

\pause 

```{r, eval = FALSE, echo=TRUE}
summary(lm_econ)
# summary(lm_rdi)
```

\pause 

\tiny

```{r, echo=TRUE, eval = TRUE}

summary(lm_econ)$r.squared

```

\pause 

\tiny

```{r, echo=TRUE, eval = TRUE}
# summary(lm_rdi)
```

<!-- Q: what kind of model of voting behavior does this imply? 
        (direct/indirect, full/partial information, sociotropic/individual) 
     A: 
     - doesn't specify direct or indirect! this model doesnt tease out
     - partial information, only looking at past quarter of growth 
     - sociotropic
-->

## Economy and PV: Fitting a model (STEP 1 \& 2)

<!-- Q: for review, how would you read this plot in ONE sentence? someone who didn't participate in lecture, please! -->

\pause 

```{r, echo=FALSE, fig.width=10, fig.height=6, out.width = '100%', fig.align='center'}
# GDP plot
dat2 %>%
  ggplot(aes(x=GDP_growth_pct, y=H_incumbent_party_majorvote_pct,
             label=year)) + 
    geom_text(size = 8) +
    geom_smooth(method="lm", formula = y ~ x) +
    geom_hline(yintercept=50, lty=2) +
    geom_vline(xintercept=0.01, lty=2) + # median
    xlab("Q8-Q7 GDP growth (X)") +
    ylab("Incumbent party PV (Y)") +
    theme_bw() +
    ggtitle("Y = 49.44 - 0.9118  * X") + 
    theme(axis.text = element_text(size = 20),
          axis.title = element_text(size = 24),
          plot.title = element_text(size = 32))

```

\pause

```{r, echo=FALSE, fig.width=10, fig.height=6, out.width = '100%', fig.align='center'}
# # RDI plot
# data2 %>%
#   ggplot(aes(x=DSPIC_change_pct, y=H_incumbent_party_majorvote_pct,
#              label=year)) + 
#     geom_text(size = 8) +
#     geom_smooth(method="lm", formula = y ~ x) +
#     geom_hline(yintercept=50, lty=2) +
#     geom_vline(xintercept=0.01, lty=2) + # median
#     xlab("Q8-Q7 pct change RDI (X)") +
#     ylab("Incumbent party PV (Y)") +
#     theme_bw() +
#     ggtitle("Y = 52.5781 - 0.7964   * X") + 
#     theme(axis.text = element_text(size = 20),
#           axis.title = element_text(size = 24),
#           plot.title = element_text(size = 32))
```

# How to evaluate your model (STEP 3)

## Tools

**Key: We want to evaluate the predictive power of our model.** 

\pause

* In-sample fit

    1. $R^2$
    2. In-sample error

\pause

* Out-of-sample testing

    1. Leave-one-out validation
    3. Cross-validation
    3. \textbf{Real} out-of-sample prediction (and see what happens...)

## Model Fit: $R^2$

\only<1>{$R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i-\widehat{y_i})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2}$}
<!-- Q: does anyone know what the top and bottom here mean? -->
\only<2->{$R^2 = 1 - \frac{\overbrace{\sum_{i=1}^{n}(y_i-\widehat{y_i})^2}^{\text{variance unexplained by model}}}{\underbrace{\sum_{i=1}^{n}(y_i-\bar{y})^2}_{\text{variance in data}}}$}

\pause says how much variation of in $Y$ values in the sample is captured by the fitted model's predicted values $\widehat{Y}$. \pause
\vskip0.2cm
```{r}
summary(lm_econ)$r.squared

```

```{r}
# summary(lm_rdi)$r.squared

```

\pause \textbf{For a univariate linear regression, this is the same as the:} \pause <!-- Q: what is this? --> \textcolor{red}{square of bivariate correlation between $X$ and $Y$ ($r_{XY}^2$)}.

## Model Fit: in-sample error and MSE

We can plot the in-sample error via \textbf{residuals}, which capture the difference between each observed value ($y_i$) and predicted value ($\widehat{y}_i = \hat{A} + \widehat{B}x_i$): \pause

```{r, fig.width=6, fig.height=4, out.width = '70%', fig.align='center'}
# GDP
plot(dat2$year, dat2$H_incumbent_party_majorvote_pct, 
     type="l",
     main="true Y (line), predicted Y (dot) for each year")
points(dat2$year, predict(lm_econ, dat2))

```

```{r, fig.width=6, fig.height=4, out.width = '70%', fig.align='center'}
# RDI
# plot(data2$year, data2$H_incumbent_party_majorvote_pct, 
#      type="l",
#      main="true Y (line), predicted Y (dot) for each year")
# points(data2$year, predict(lm_rdi, data2))

```

## Model Fit: in-sample error and MSE

We can plot the in-sample error via \textbf{residuals}, which capture the difference between each observed value ($y_i$) and predicted value ($\widehat{y}_i = \hat{A} + \widehat{B}x_i$):

```{r, fig.width=6, fig.height=4, out.width = '70%', fig.align='center'}
# GDP
hist(lm_econ$model$H_incumbent_party_majorvote_pct - 
       lm_econ$fitted.values, 
     main="histogram of true Y - predicted Y")
# # RDI
# hist(lm_rdi$model$H_incumbent_party_majorvote_pct - 
#        lm_rdi$fitted.values, 
#      main="histogram of true Y - predicted Y")
```

## Model Fit: in-sample error and MSE

We can summarise the error a single number, such as the \textbf{mean-squared error (MSE)}:

```{r}
# GDP
mse_g <- mean((lm_econ$model$H_incumbent_party_majorvote_pct - 
                 lm_econ$fitted.values)^2)
sqrt(mse_g)

# # RDI
# mse_r <- mean((lm_rdi$model$H_incumbent_party_majorvote_pct - 
#                  lm_rdi$fitted.values)^2)
# sqrt(mse_r)
```
\textcolor{red}{This is hard to interpret on its own, more useful in comparison with other models.}

## Model Testing
\pause
Checking in-sample model predictions is a good baseline evaluation, but it feels a bit like "cheating" \pause $\rightsquigarrow$ can we take away the model's "answer key"? \pause

<!--the best test of a model's predictive score -- simulate out-of-sample 
    prediction and check performance against ground-truth; in-sample is sort of 
    easy because it's double dipping the data, this is a harder test!-->

We can simulate \textbf{out-of-sample prediction} (also called out-of-sample testing) by withholding some observation, e.g. $X_{2018}$, before fitting: \pause

```{r}
# GDP
outsamp_mod1 <- lm(H_incumbent_party_majorvote_pct ~ GDP_growth_pct, 
                    dat2[dat2$year != 2018,])
outsamp_pred <- predict(outsamp_mod1, 
                        dat2[dat2$year == 2018,])
outsamp_true <- dat2$H_incumbent_party_majorvote_pct[dat2$year == 2018] 
```
\pause and see how well the model predicts the true $Y_{2018}$ for the held-out observation $X_{2018}$:
```{r}
outsamp_pred - outsamp_true
```
Leaving a single observation out and testing the model against the ground truth is, \pause you guessed it, called \textbf{leave-one-out validation}.

## Model Testing

\textbf{Cross-validation}: withold a *random subset* of the sample, fit model on rest of sample, and evaluate predictive performance on the held-out observations. \pause

<!-- Me: predicts 2016 within 2 points..but ok 2016 was weird -->


```{r}
# GDP
years_outsamp <- sample(dat2$year, 8)
mod <- lm(H_incumbent_party_majorvote_pct ~ GDP_growth_pct,
          dat2[!(dat2$year %in% years_outsamp),])
outsamp_pred <- predict(mod,
                newdata = dat2[dat2$year %in% 
                                 years_outsamp,])
```
\pause
```{r}
mean(outsamp_pred - dat2$H_incumbent_party_majorvote_pct[dat2$year 
                                                         %in% years_outsamp])
```
\pause \textcolor{red}{But we don't want to do this just once.}

## Model Testing

Cross-validation involves repeatedly evaluating performance against many randomly held-out "out-of-sample" datasets:

<!-- we can do this many times and see how out-of-sample performance usually is -->
```{r, eval=FALSE}
years_outsamp <- sample(dat2$year, 8)
outsamp_mod <- lm(H_incumbent_party_majorvote_pct ~ 
                    GDP_growth_pct,
                  dat2[!(dat2$year %in% years_outsamp),])
outsamp_pred <- predict(outsamp_mod,
                newdata = dat2[dat2$year %in% years_outsamp,])
outsamp_true <- dat2$H_incumbent_party_majorvote_pct[dat2$year 
                                                     %in% years_outsamp]
mean(outsamp_pred - outsamp_true)
```

## Model Testing

Cross-validation involves repeatedly evaluating performance against many randomly held-out "out-of-sample" datasets:

```{r}
outsamp_errors <- sapply(1:1000, function(i){
    years_outsamp <- sample(dat2$year, 8)
  outsamp_mod <- lm(H_incumbent_party_majorvote_pct ~ 
                      GDP_growth_pct,
                  dat2[!(dat2$year %in% years_outsamp),])
  outsamp_pred <- predict(outsamp_mod,
                newdata = dat2[dat2$year %in% years_outsamp,])
  outsamp_true <- dat2$H_incumbent_party_majorvote_pct[dat2$year 
                                                       %in% years_outsamp]
  mean(outsamp_pred - outsamp_true)
})
```


##  Model Testing

We can then look at a distribution of evaluations, rather than one single evaluation: \pause
```{r, echo=FALSE, message=FALSE, fig.width=6, fig.height=3, out.width = '70%', fig.align='center'}
hist(outsamp_errors,
     xlab = "",
     main = "mean out-of-sample residual\n(1000 runs of cross-validation)")
```
```{r}
mean(abs(outsamp_errors))
```

## Economy and PV: Out-of-sample prediction (STEP 4 \& 5)

Ok, now let's say we're happy with our model. \pause
Plug in the 2nd quarter GDP growth this year:

```{r, echo=TRUE, eval=FALSE}
GDP_new <- economy_df %>%
    subset(year == 2020 & quarter_cycle == 8) %>%
    select(GDP_growth_pct)

predict(lm_econ, GDP_new)
```
\pause
```{r, echo=FALSE, eval=TRUE}
GDP_new <- economy_df %>%
    subset(year == 2020 & quarter_cycle == 8) %>%
    select(GDP_growth_pct)

predict(lm_econ, GDP_new)
```


## Economy and PV: Prediction uncertainty (STEP 6)

```{r, eval=FALSE, echo=TRUE}
predict(lm_econ, GDP_new, interval="prediction")
```
\pause
```{r, eval=TRUE, echo=FALSE}
predict(lm_econ, GDP_new, interval="prediction")
```

## What's wrong with a "fundamentals-only" forecast for 2020?

Replicating [New York Times](https://www.nytimes.com/2020/07/30/business/economy/q2-gdp-coronavirus-economy.html): \pause

```{r, echo=FALSE, message=FALSE, fig.width=7, fig.height=4, out.width = '80%', fig.align='center'}
economy_df %>%
    subset(quarter_yr == 2 & !is.na(GDP_growth_qt)) %>%
    ggplot(aes(x=year, y=GDP_growth_qt,
               fill = (GDP_growth_qt > 0))) +
    geom_col() +
    xlab("Year") +
    ylab("GDP Growth (Second Quarter)") +
    ggtitle("The percentage decrease in G.D.P. is by far the biggest on record.") +
    theme_bw() +
    theme(legend.position="none",
          plot.title = element_text(size = 12,
                                    hjust = 0.5,
                                    face="bold"))
```

\small \pause

<!-- "Biden is currently on track to win nearly 1,000 electoral votes — a bit of a problem since the maximum number theoretically achievable is 538. (Silver)" \pause -->

\textbf{Extrapolation}: Forecasting a DV from an observation of $X_{new}$ *much smaller or bigger* than any $x_1,\ldots,x_n$ in sample used to fit model.

\normalsize

# How to improve your model

## Most obvious: Choice of measure for IV

So many options for GDP growth:
<!-- Q: what is the behavioral model it assumes? -->

  * Ex. Q8 of election year vs aggregate GDP growth for 2 years (8 quarters).
  * Latter makes sense but implies a stronger behavioral model \pause (\textcolor{red}{full information, rational calculus, retrospective voting}).

```{r, echo=FALSE, message=FALSE, fig.width=6, fig.height=4, out.width = '70%', fig.align='center'}
aggregate <- economy_df %>%
    subset(year %in% economy_df$year & quarter_cycle == 5) %>%
    mutate(GDP_growth_total = (GDPC1 - lag(GDPC1))/lag(GDPC1)) %>%
    select(year, GDP_growth_total) 

agg <- dat2 %>%
    left_join(aggregate) %>%
    filter(!is.na(GDP_growth_total)) 

agg %>%
    ggplot(aes(x=GDP_growth_total, y=H_incumbent_party_majorvote_pct,
             label=year)) + 
    geom_text() +
    geom_smooth(method="lm", formula = y ~ x) +
    geom_hline(yintercept=50, lty=2) +
    geom_vline(xintercept=0.13, lty=2) + # median
    xlab("Aggregate GDP growth") +
    ylab("Incumbent party PV") +
    theme_bw()

```

## Most obvious: Choice of measure for IV

<!-- Economy model tends to be single-variate. But even in a single variable model... -->

Multiple measures of economic performance!
<!-- Q: (if time), anyone know how GDP is actually calculated? -->

    * GDP growth
    * Real disposable income
    * Unemployment
    * Inflation

\pause \textcolor{red}{Another option is to include multiple economic IVs $X_1,X_2,\ldots$ in our model, since they capture \underline{different dimensions} of the economy.}
    
## Multiple IVs

What's one potential draw-back of throwing a "kitchen sink" of IVs into a model?
\pause
<!-- Q: ask them this -->
IVs may be **multicollinear**, that is highly correlated and therefore, in a sense, redundant  \pause $\rightsquigarrow$ IVs are no longer independent variables!

```{r}
cor(agg$GDP_growth_pct, agg$GDP_growth_total)

```

\pause We want models that capture the complexities of the real world, but that are also parsimonious (why? will explore this in the future).

## Blog Extensions

1. \textbf{Model Evaluation.} Build multiple predictive models using national economic variables as predictors. Compare those models using the tools we learned today. How much is your 2022 prediction sensitive to the change of measure(s)? What does it tell us about the economic model of voting behavior?

2. \textbf{Heterogenous Predictive Power of the Economy.} Does the effect of the economy vary when we consider popular vote versus seat share as our outcome (dependent) variable? Does the predictive power of economy change across time? If so, why?

3. \textbf{Local Economy.} We can think of a behavioral model where voters base their decisions not on national economy but on their local economy (or both!). Build a predictive model for 2022 using unemployment data at the state level: `unemployment_state_monthly.csv`. You can use popular vote or seat share as your outcome variable. Does this improve predictive power compared to solely focusing on national economy?

