---
title: Final Prediction
author: Hannah Valencia
date: '2022-11-04'
slug: []
categories: []
tags: []
summary: "Over the past nine weeks, we have explored a multitude of variables that may impact election outcomes in an attempt to forecast the 2022 midterm election. We have learned about economic forces, polling, expert predictions, incumbency, advertising, campaigning, and more to find if they hold any predictive power, and how together in a model they may foreshadow what is to come in the results next week. In this blog, I will create a final prediction model for the House of Representatives and share its results, with the intention of reflecting on it after the election." 
---

*This blog is part of a series related to Gov 1347: Election Analytics, a course at [Harvard University](https://www.harvard.edu/) taught by Professor [Ryan D. Enos](http://ryandenos.com/)*.

*Over the past nine weeks, we have explored a multitude of variables that may impact election outcomes in an attempt to forecast the 2022 midterm election. We have learned about economic forces, polling, expert predictions, incumbency, advertising, campaigning, and more to find if they hold any predictive power, and how together in a model they may foreshadow what is to come in the results next week. In this blog, I will create a final prediction model for the House of Representatives and share its results, with the intention of reflecting on it after the election.*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# load libraries

library(tidyverse)
library(usmap)
library(plotly)
library(rmapshaper)
library(sf)
library(haven)
library(stringr)
library(sjlabelled)
library(usdata)
library(ggpubr)
library(stargazer)

```

```{r}

# reading in data

distdata <- read_csv("fulldata.csv") # master df by district
natldata <- read_csv("data2.csv", skip = 1) # master df 
popvote_df <- read_csv("popvote_df.csv", skip = 1, col_types = cols(...1 = col_skip(), ...2 = col_skip()))
rdi_df <- read_csv("RDI_quarterly.csv") %>% select(!`...1`)
qtnatl <- read_csv("data1.csv") %>% select(!c(`...1`, `...2`))
gallup_approval <- read_csv("Gallup approval.csv")
```

### Background

Since this class first convened in the beginning of September, we have time and time again been reminded of the shortcomings of election forecasting. Elections are fickle and there is no way to know for certain how voters will vote on election day. The experts oftentimes cannot predict what will happen, if an election will be toss-up or a landslide. There are shocks that no one sees coming, costs of voting that may be unanticipated, various biases with polling, and ever-changing political opinions that result from all sorts of issues and news. While these unknowns make forecasting very difficult, we have gained the tools over the last nine weeks that give us a good foundation to create predictions of our own for the House of Representatives midterm election.

### My Model Choices

In building my model, the first choice I had was what to use as my dependent variable and the level on which to predict on. For my dependent variable, I decided to run models for both Democratic seat share and Democratic vote share to see the results of both and how they may unveil different stories about the election. I also created variables putting the vote share and seat share in terms of the incumbent party to see how incumbents perform without paying specific attention to their party affiliation, but I decided that this approach would complicate interpreting results. While we spent multiple weeks working with district-level data and forecasting each of the 435 districts, in the end I have decided to predict vote share and seat share on the national level. We have more data for these variables and do not have to rely upon things like pooling, that may produce greater margins for error. Given the insufficient district-level data, a pooled model would have allowed us to take data from neighboring, similar districts and count it as its own. However, my national model was heading in the right direction in terms of improving predictability, and the lack of district data led me to decide on a national-level final model. 

In the first week of class, we looked at the fundamentals of election forecasting models, with predictors like the president's party. We learned about the phenomenon that takes place in most midterms where the president's party tends to lose seats [(Campbell 2018)](https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/abs/introduction-forecasting-the-2018-us-midterm-elections/6BA191A0140468E022ECCE67D1CDA03B). Following these basics, in week two we looked at how Real Disposable Income (RDI) on its own does a decent job of predicting elections. We also took a look at a slew of other economic variables, such as the Consumer Price Index (CPI), GDP growth rate, unemployment, and more. Despite the overlap between the government and the economy, most of these variables proved to be insignificant and poor predictors for the House elections. The one economic variable I will be using in my final model the unemployment rate, as it is typically a decent indicator of the health of the economy. In addition to using it on its own, I have also decided to interact it with the president's party. The most important topics to voters vary based on their political party affiliation, and Republicans are known to weigh economic factors more heavily. Therefore, an interaction term between party and unemployment rate can provide us with more significant results than the two can separately on their own.

We continued on from the fundamentals and economic variables onto polling, looking at the generic ballot as well as district-level polls. When adding these polls to my model, I had limited the data to 1990 and later, justifying this with the fact that polling methods have greatly changed since 1945 when the data was first captured. It was my hope that in reducing the sample, the model would better predict recent elections. While I think this justification still makes sense, especially for district-level polling where there does not exist much data even today, I will not be limiting the data by year as severely. In my final model, the only polling data I will be using is the generic ballot, measuring which party people support without regard for specific candidates. The data I will be using goes back to 1960, which is when all the variables of my interest have data for. It would still make sense to limit the data to more recent years for the same polling reasons, but since I am only dealing with the generic ballot, I believe the changing polling methods will not hinder the predictability of the model and it will be more useful to have the longer data.

While we did not dedicate much time in class to discussing presidential approval ratings and their impact on elections, some classmates and I spoke about incorporating it as another form of polling that has easily accessible historical data. I gathered data on presidential approval from [Gallup Analytics](https://analyticscampus-gallup-com.ezp-prod1.hul.harvard.edu/Tables) that date back to 1960. Polling dates varied year to year, so I decided pulled the president's approval rating from whichever the last poll right before the election was. A few years in the 1960s and 1970s, this ended up being polls that were taken from June-August of the election year, but for most other years and especially in more recent history, the ratings are from the final weeks of October. While it would have been nice to have a specific date that the approval rating was pulled from consistently every year, I believe using the poll prior to the election will mitigate any issue.

Incumbency has also been a popular word throughout our class, and it is proven as a good predictor for the House of Representatives elections. Looking at the district-level data we have from 1945-2020, we find that the incumbent wins the House race about 84% of the time. Below is a bar graph showing this relationship.

```{r}
distdata %>%
  group_by(winner_candidate_inc) %>%
  summarize(count = n()) %>%
  mutate(pct_inc = count/sum(count)) %>%
  ggplot(aes(x = winner_candidate_inc, y = pct_inc, fill = winner_candidate_inc)) +
  geom_bar(stat = "identity", fill = c("dodgerblue1", "dodgerblue4")) +
  labs(x = "Winning Candidate Incumbency Status",
       y = "Percent",
       title = "Percent of Incumbents That Win House Elections (1945-2020)") +
  theme(legend.position = "none")
```

While this data is important at the district level, we learned about other incumbency phenomena that take place at a national level, such as the house flipping at midterm elections and the President's party losing seats. Despite this incumbency data surely boasting high predictive power at the district-level, it does not provide much to us on a national-level. In a similar vein, however, rather than looking at the House majority incumbent from the year before, we can use the previous election's vote share and seat share to predict that of the following election. I created lagged variables for both of these variables and will incorporate them into my final model, along with the President's party variable that I previously mentioned.

The final variable I will be using in my model is an indicator variable for if the election takes place in a midterm year or not. From our discussions and readings, we know that different types of voters come out for midterm elections than presidential elections. We also learned in class that many Americans do not even know who their representative is. Those who vote in a midterm year are likely more involved politically and stay up-to-date with the news. I also will be interacting this term with the president's party variable with the thought that it could account for some of the seat flipping that we historically see. Since 1955, every house flip has been the result of a midterm election [(Reuters)](https://www.reuters.com/graphics/USA-ELECTION/MIDTERMS/gdpzyzowgvw/index.html). This interaction term can account for the additional incumbent losses that occur during midterms but not during election years.

Throughout our time this semester, we have also worked with multiple other district-level variables that I will not be including in my model. We learned about advertising and the amount parties spend on advertising. In [Gerber et al. 2011](https://hollis.harvard.edu/primo-explore/fulldisplay?docid=TN_cdi_proquest_miscellaneous_881466543&context=PC&vid=HVD2&search_scope=everything&tab=everything&lang=en_US) the authors found that "televised ads have strong but short-lived effects on voting preferences". With this in mind, along with in-class discussions about advertising data being unreliable and sometimes unavailable, I decided to forego using it in my model. Other district-level variables such as the cost of voting, ground campaigning efforts, and voter turnout I will not be adjusting to incorporate into my national model.

### Formulas

Given all the data we have considered using this semester, and after many rounds of trial and error, I have created two final models. Below are the model equations and their corresponding regression tables using the national data that we are working with.

##### Democratic Vote Share

$$
Democratic Vote Share = \beta_0 + Generic Ballot Democrat\beta_1 + Lag House Dem Vote Share\beta_2 + President Party R\beta_3 + President Approval\beta_4 + Midterm\beta_5 + Unemployment Rate\beta_6 + President Party R * Midterm\beta_7 + President Party R * Unemployment\beta_8
$$


```{r}

# recreating Professor Enos's graph from week 1 illustrating the relationship between percent change RDI and the seat change in the president's party

# adding seat share and president party to the data frame with national-level data

a <- distdata %>%
  distinct(year, president_party)

b <- popvote_df %>%
  select(year, R_seats, D_seats, Other_seats)

natldata1 <- left_join(natldata, a, by = c("year" = "year"))
natldata1 <- left_join(natldata1, b, by = c("year" = "year")) %>% select(!`...1`)

# lagging the seats to create a variable that has the seat change for the President's party

c <- b %>%
  mutate(year = year + 2) %>%
  rename(R_seats_previous = R_seats,
         D_seats_previous = D_seats,
         Other_seats_previous = Other_seats)

natldata1 <- left_join(natldata1, c, by = c("year" = "year"))

natldata1 <- natldata1 %>%
  mutate(pres_party_seat_change = ifelse(president_party == "R", (R_seats - R_seats_previous), (D_seats - D_seats_previous)))

# creating a variable for the percent change in RDI for each election year
# coded as the percent change in RDI from Q3 of the election year (aka Q7) from the RDI from Q3 of the previous year

rdi_df1 <- rdi_df %>%
  mutate(election_year = 1:nrow(rdi_df) %/% 8,
         election_year = lag(election_year, default = 0)) %>%
  group_by(election_year) %>%
  filter(election_year != 31) %>%
  mutate(pct_rdi_election = (DSPIC_qt[quarter_cycle == 7] - DSPIC_qt[quarter_cycle == 3])/DSPIC_qt[quarter_cycle == 3]*100)

rdi_df1 <- rdi_df1 %>%
  distinct(year, pct_rdi_election)

natldata1 <- left_join(natldata1, rdi_df1, by = c("year" = "year"))

# For some reason the graph I produce is different than that of Professor Enos's, likely due to slight differences in the way we coded the variables.
# Even though I will not include the recreated graph in this post, I have the same new variables that I can possibly incorporate into a model or graph later on.

# x <- natldata1 %>% select(year, pres_party_seat_change, pct_rdi_election)

# natldata1 %>%
#   ggplot(aes(x = pct_rdi_election, y = pres_party_seat_change, label = year)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = TRUE, alpha = .25,size = 2) +
#   labs(title = "Descriptive Relationship Between RDI Change and \n President's Party Seat Change in House",
#        x = "Percent Change in RDI",
#        y = "President's Party Seat Change",
#        caption = "RDI = Real Disposable Income, Midterm years in black, \n change from Q3 of election year - 1 year") +
#   scale_color_manual(values=c("darkgrey","black")) +
#   scale_y_continuous(breaks = seq(-60, 40, by = 10)) +
#   theme(legend.position = "none")
```

```{r}

d <- distdata %>%
  select(year, gen_avg_dem, gen_avg_rep) %>%
  distinct(year, gen_avg_dem, gen_avg_rep)

e <- qtnatl %>%
  distinct(year, R_majorvote_pct, D_majorvote_pct)

natldata1 <- left_join(natldata1, d, by = c("year" = "year"))
natldata1 <- left_join(natldata1, e, by = c("year" = "year"))

# creating two new dependent variables in case I want to try them out
# vote share and seat share for the president's party rather than just the democratic and republican ones

natldata1 <- natldata1 %>%
  mutate(pres_party_vote_pct = ifelse(president_party == "D", D_majorvote_pct, R_majorvote_pct),
         pres_party_seat_share = ifelse(president_party == "D", DemSeatShare, RepSeatShare))

# creating a variable for if the year is a midterm election year

natldata2 <- natldata1
natldata2$midterm <- seq_len(nrow(natldata2)) %% 2L + 1L
natldata2$midterm[natldata2$midterm == 2] <- 0

# adding presidential approval ratings for each year from Gallup Analytics

natldata2 <- left_join(natldata2, gallup_approval, by = c("year" = "year"))

# adding lagged vote share
f <- natldata2 %>%
  mutate(year = year + 2,
         DemVS_prev = D_majorvote_pct) %>%
  select(year, DemVS_prev)

# googled the seat share for 1958 to fill in for 1960's lag

natldata2 <- left_join(natldata2, f, by = c("year" = "year"))
natldata2$DemVS_prev[natldata2$year == 1960] <- 56.0

# adding lagged seat share to get same effect as the lagged vote share but for the seat share model
g <- natldata2 %>%
  mutate(year = year + 2,
         DemSeatShare_prev = DemSeatShare) %>%
  select(year, DemSeatShare_prev)

# googled the seat share for 1958 to fill in for 1960's lag

natldata2 <- left_join(natldata2, g, by = c("year" = "year"))
natldata2$DemSeatShare_prev[natldata2$year == 1960] <- (283/435)

# changing the format of the seat share variable to match that of vote share (ex. 56 instead of 0.56)
natldata2 <- natldata2 %>%
  mutate(DemSeatShare = DemSeatShare * 100)


```

```{r, results='asis'}

# modelling Democratic vote share

fit1a <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem)
#summary(fit1a) 

fit1b <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev)
#summary(fit1b)

fit1c <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev + president_party)
#summary(fit1c)

fit1d <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev + president_party + approval_rating)
#summary(fit1d)

fit1e <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev + president_party + approval_rating + midterm*president_party)
#summary(fit1e)

fit1f <- lm(data = natldata2, D_majorvote_pct ~ gen_avg_dem + DemVS_prev + president_party + approval_rating + midterm*president_party + unrate + unrate*president_party)
# summary(fit1f)

stargazer(fit1a, fit1b, fit1c, fit1d, fit1e, fit1f, type = "html", covariate.labels = c("Generic Ballot Support - D", "Lag House Dem VS", "President Party - R", "President Approval Rating", "Midterm Year", "Unemployment Rate", "President Party - R * Midterm Year", "President Party - R * Unemployment", "Constant"))

```


Model 6 is my final model for the Democratic Vote Share, the other models in this regression table simply show how each variable impacts and improves the model one step at a time. In this model, we see that all the variables are significant at the 0.1 significance level, and most at the 0.05 level. While approval rating and the lag of the House democratic vote share are the only variables that were not immediately significant when first added to the model, they both increased the R-squared and adjusted R-squared values, and eventually found a level of significance by the final model. Model 6 has an R-squared of 0.767 and an adjusted R-squared of 0.6822. I did some testing with other variables, but adding any of the other variables I was considering (such as percent change RDI) ended up decreasing the adjusted R-squared. The most significant variables in this model are the indicator variable for whether the election is a midterm election and the interaction between this indicator and the president's party.

In this model, every one percentage point support in the generic ballot for democrats increases the Democratic vote share percent by 0.229. This positive relationship makes sense, as we expect democratic vote share to be higher in years when people feel more favorably towards the party all around. Every additional percentage point in the previous year's democratic vote percentage for the house predicts a 0.426 percentage point increase in the democratic vote share. Again, this positive relationship is very intuitive. 

When the President is a Republican, this negatively impacts democratic vote share for the house, lowering democratic vote share by -6.339. The relationship that we have discussed with the president's party losing seats in the house was mainly in midterm years, which we see in the interaction term between president's party and midterm year. The coefficient on this interaction term is a *positive* 6.793, which tells us in midterm years when the President is a Republican, democratic vote share increases slightly from this interaction. When we first added the president's party variable to Model 3, prior to any interaction, we see it was significant and positive. In this simplified model we can interpret the coefficient to tell us that across all years, a Republican president is predicted to positively impact House democratic vote share. When it is not a midterm year, however, the president's party aligns with the way voters vote for House representatives: a Republican president hurts democratic vote share.

While Presidential approval rating was not significant in either Model 4 or 5, it found significance in Model 6. The approval rating is on a scale from 0-1, with the percentages represented as decimals rather than whole numbers like some of the other variables. When a president has an approval of 1, or 100%, this *decreases* democratic vote share by 5.435% in the model. This variable would be easier to explain if the dependent variable was president party's vote share, rather than democratic vote share, as it would be independent of party. Approval ratings do not often fall at either extreme, with most falling between 40-50%. With this in mind, the magnitude of the decrease in vote share decreases, but the intuition behind the sign of the coefficient remains ambiguous. 

Looking at the unemployment rate coefficient and the interaction between it and the president's party there are a few things to note. First, it is important to know that the variable is coded as the unemployment rate in Quarter 3 (July to September) as reported by the Bureau of Labor Statistics. The unemployment rate coefficient is -0.690, telling us that for every percentage point increase in the unemployment rate, the democratic vote share percentage declines by 0.69 when the president is a Democrat. When the President is a Republican, however, the interaction term of 0.793 comes into play and creates a 0.103 percentage point *increase* in democratic vote share. This tells us that when unemployment is high, people likely blame the party of the president in power, and thus vote in opposition to that party.


##### Deomcratic Seat Share

$$
Democratic Seat Share = \beta_0 + Generic Ballot Democrat\beta_1 + Lag House Dem Seat Share\beta_2 + President Party R\beta_3 + President Approval\beta_4 + Midterm\beta_5 + Unemployment Rate\beta_6 + President Party R * Midterm\beta_7 + President Party R * Unemployment\beta_8
$$


```{r, results = 'asis'}

natldata2 <- natldata2 %>% mutate(DemSeatShare_prev = DemSeatShare_prev*100)

# modelling Democratic seat share

fit2a <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem)
#summary(fit2a) 

fit2b <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev)
#summary(fit2b)

fit2c <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev + president_party)
#summary(fit2c)

fit2d <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev + president_party + approval_rating)
#summary(fit2d)

fit2e <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev + president_party + approval_rating + midterm*president_party)
#summary(fit2e)

fit2f <- lm(data = natldata2, DemSeatShare ~ gen_avg_dem + DemSeatShare_prev + president_party + approval_rating + midterm*president_party + unrate + unrate*president_party)
#summary(fit2f)

stargazer(fit2a, fit2b, fit2c, fit2d, fit2e, fit2f, type = "html", covariate.labels = c("Generic Ballot Support - D", "Lag House Dem Seat Share", "President Party - R", "President Approval Rating", "Midterm Year", "Unemployment Rate", "President Party - R * Midterm Year", "President Party - R * Unemployment", "Constant"))

```


Running the same regression again, but replacing vote share with seat share for both the dependent variable as well as the lagged independent variable, I found similar results. However, there were a couple of variables whose significance did not hold in the seat share model. We see that the variable for the president's approval rating does not have any significance across any of the three models it is incorporated into and has very high standard errors. Additionally, the interaction between the President's party and the unemployment rate do not hold significance in this model either. Despite these insignificant variables, their presence improves the adjusted R-squared so I have decided to leave them in. Similar to the vote share model, we again find the most significant variables to be the indicator variable for whether the election is a midterm election and the interaction between this indicator and the president's party. In addition, this model also shows the lag of seat share to be a highly significant variable. Slightly improving on the r-squared and adjusted r-squared of the vote share model, my final model here has an r-squared of 0.807 and an adjusted r-squared of 0.736.

In changing the dependent variable, we do not see any changes in the signs of the final model coefficients. Even though the magnitudes of the coefficients vary slightly, the overall effects of each variable on the democratic seat share percentage remain. 


### Midterm Models

After looking at both of those models that use data across all elections from 1960-2020, I wanted to see how these models would change if I limited the data to only midterm election years. As previously discussed, there is a different voting body in midterm elections versus presidential elections. In limiting the years I model on, I am hoping to improve their predictive power.

I removed the midterm indicator variable since the filter takes care of that, and also removed unemployment rate due to it causing a significant decrease in the adjusted r-squared. This left me with just the generic ballot support for democrats, the president's party, and the previous democratic vote/seat share as independent variables. I ran this model on both vote share and seat share, and below are the results of this inquiry. 

```{r, results = 'asis'}

# trying new models only using midterm years

midtermdata <- natldata2 %>%
  filter(midterm == 1)

fit3a <- lm(data = midtermdata, D_majorvote_pct ~ gen_avg_dem)
#summary(fit3a) 

fit3b <- lm(data = midtermdata, D_majorvote_pct ~ gen_avg_dem + president_party)
#summary(fit3b)

fit3c <- lm(data = midtermdata, D_majorvote_pct ~ gen_avg_dem + president_party + DemVS_prev)
#summary(fit3c)

stargazer(fit3a, fit3b, fit3c, type = "html", covariate.labels = c("Generic Ballot Support - D", "President Party - R", "Lag House Dem VS"))


# seat share model for only midterm years

fit4a <- lm(data = midtermdata, DemSeatShare ~ gen_avg_dem)
#summary(fit4a) 

fit4b <- lm(data = midtermdata, DemSeatShare ~ gen_avg_dem + president_party)
#summary(fit4b)

fit4c <- lm(data = midtermdata, DemSeatShare ~ gen_avg_dem + president_party + DemSeatShare_prev)
#summary(fit4c)

stargazer(fit4a, fit4b, fit4c, type = "html", covariate.labels = c("Generic Ballot Support - D", "President Party - R", "Lag House Dem Seat Share"))

```

Both of these models have higher R-squared and adjusted R-squared values than their all-elections counterpart, with the vote share model boasting a 0.801 r-squared, and the seat share model having a 0.840. 

The lag of Democratic house vote share in the vote share model is insignificant, but improves the R-squared and adjusted r-squared so I kept it in - as well as for consistency.

### 2022 Predictions

Using generic ballot data from FiveThirtyEight, Biden approval ratings from Gallup, and the 2022 Q3 unemployment rate from the BLS, I have predictions for each of the four models, including their 95% confidence interval, as noted by "lwr" and "upr":

Democratic Vote Share using all years
```{r}

# creating a dataframe with the 2022 independent variables data

data2022 <- data.frame(gen_avg_dem = 45.5, # fivethirtyeight
                       DemVS_prev = natldata2$D_majorvote_pct[natldata2$year == 2020],
                       DemSeatShare_prev = natldata2$DemSeatShare[natldata2$year == 2020],
                       president_party = "D",
                       approval_rating = 0.40, # gallup
                       midterm = 1,
                       unrate = 3.7) # bls

# predicting the 2022 election using each model

predict(fit1f, data2022, interval = "confidence") # Democratic Vote Share using all years

```

Democratic Seat Share using all years
```{r}
predict(fit2f, data2022, interval = "confidence") # Democratic Seat Share using all years
```

Democratic Vote Share using midterm years
```{r}
predict(fit3c, data2022, interval = "confidence") # Democratic Vote Share using midterm years
```

Democratic Seat Share using midterm years
```{r}
predict(fit4c, data2022, interval = "confidence") # Democratic Seat Share using midterm years
```

The predictions for the first two models that used data across all years are slightly higher than I would expect, specifically for the seat share. The seat share here is predicted to be split just about 50/50, which most experts do *not* believe will be the case this year. The models using data only from midterm elections, however, seem like they will more accurately predict this years election, at least in terms of being closer to what the experts are saying.

The two midterm-only models also have confidence intervals that do not cross 50%, meaning that they are 95% confident that the Democrats will not have more than 50% of the two-party vote share nor the seat share, meaning Republicans will win the house.

The model of Democratic Seat Share using midterm years predicts that Democrats will win 202 seats in the House, thus losing their majority, compared to the 219 that are predicted in the model that goes across all years.

### In-Sample Testing

To validate this model, I conducted in-sample testing, predicting the vote and seat shares for each year within the model. I took these predictions and plotted them against the actual vote and seat shares in those years, producing the following graphs. The R-squared value of each model is also reflected on the plot. An R-squared of 1 would mean the model perfectly predicts the outcome.

In each graph I also added the 2022 predictions from the regression models. While the second model had the highest R-squared in its in-sample validation, based on what we know about the expert forecasts for this year's election it seems a bit too high of a prediction. This prediction of a 50.50952 seat share for democrats is equivalent to 220 seats for Democrats. The fourth model had the lowest R-squared for its validation, but it had the *highest* R-squared out of all four regressions.


```{r}
# in sample testing
# creating empty columns for the predictions of each of my four final models

natldata2$prediction1 <- NA
natldata2$prediction2 <- NA
natldata2$prediction3 <- NA
natldata2$prediction4 <- NA

# creating a for loop that fills in the data frame with the predictions for each model for every year

for (i in 1960:2020){
  x <- natldata2 %>%
    filter(year == i) %>%
    select(gen_avg_dem,DemVS_prev,DemSeatShare_prev, president_party, approval_rating, midterm, unrate)
  
  natldata2$prediction1[natldata2$year == i] <- predict(fit1f, x, interval = "confidence")[1]
  natldata2$prediction2[natldata2$year == i] <- predict(fit2f, x, interval = "confidence")[1] 
  natldata2$prediction3[natldata2$year == i] <- predict(fit3c, x, interval = "confidence")[1] 
  natldata2$prediction4[natldata2$year == i] <- predict(fit4c, x, interval = "confidence")[1] 
}

```

```{r}

# Dem VS all years plot

natldata2 %>%
  ggplot(aes(x = prediction1, y = D_majorvote_pct, label = year)) +
  geom_point() +
  geom_abline(y = x, color = "red") +
  geom_text(hjust=0, vjust=0, size = 3) +
  labs(x = "Predicted Democratic Vote Share (all years)",
       y = "Actual Democratic Vote Share",
       title = "Actual vs. Predicted Democratic Vote Share (all years)") +
  stat_cor(method="pearson") +
  geom_point(aes(x=50.20221, y=50.20221, label = "2022"), colour="dodgerblue3") +
  geom_text(aes(x=50.20221, y=50.7, label = "2022"), color = "dodgerblue3", size = 3.5)

```

```{r}
# Dem Seat Share all years plot

natldata2 %>%
  ggplot(aes(x = prediction2, y = DemSeatShare, label = year)) +
  geom_point() +
  geom_abline(y = x, color = "red") +
  geom_text(hjust=0, vjust=0, size = 3) +
  labs(x = "Predicted Democratic Seat Share (all years)",
       y = "Actual Democratic Seat Share",
       title = "Actual vs. Predicted Democratic Seat Share (all years)") +
  stat_cor(method="pearson") +
  geom_point(aes(x=50.50952, y=50.50952, label = "2022"), colour="dodgerblue3") +
  geom_text(aes(x=50.25, y=51.25, label = "2022"), color = "dodgerblue3", size = 3.5)

```

```{r}

# Dem VS midterm years plot

natldata2 %>%
  filter(midterm == 1) %>%
  ggplot(aes(x = prediction3, y = D_majorvote_pct, label = year)) +
  geom_point() +
  geom_abline(y = x, color = "red") +
  geom_text(hjust=0, vjust=0, size = 3) +
  labs(x = "Predicted Democratic Vote Share (midterm years)",
       y = "Actual Democratic Vote Share",
       title = "Actual vs. Predicted Democratic Vote Share (midterm years)") +
  stat_cor(method="pearson") +
  geom_point(aes(x=47.85624, y=47.85624, label = "2022"), colour="dodgerblue3") +
  geom_text(aes(x=47.75, y=48.25, label = "2022"), color = "dodgerblue3", size = 3.5)

```

```{r}

# Dem Seat Share midterm years plot

natldata2 %>%
  filter(midterm == 1) %>%
  ggplot(aes(x = prediction4, y = D_majorvote_pct, label = year)) +
  geom_point() +
  geom_abline(y = x, color = "red") +
  geom_text(hjust=0, vjust=0, size = 3) +
  labs(x = "Predicted Democratic Seat Share (midterm years)",
       y = "Actual Democratic Seat Share",
       title = "Actual vs. Predicted Democratic Seat Share (midterm years)") +
  stat_cor(method="pearson") +
  geom_point(aes(x=46.38345, y=46.38345, label = "2022"), colour="dodgerblue3") +
  geom_text(aes(x=45.9, y=46.8, label = "2022"), color = "dodgerblue3", size = 3.5)

```

Looking at these plots, they all have fairly high R-squareds, which instills confidence into our predictions. Surprisingly, the seat share across all years has the highest R-squared of 0.9, when its prediciton of the democrats winning 220 seats seemed very off. Both vote share models have similar accuracy, with the midterm years one having an R-squared of 0.88 and the all years one having an R-squared of 0.89. The midterm years seat share model has the lowest accuracy, with an R-squared of 0.83, which is still high, but relative to the others, low.


### Conclusion

The chart below shows my results from the seat share models and compares it to the current house make-up.

```{r}
plot <- data.frame(seats = c(220, 3, 212, 202, 0, 233, 220, 0, 215),
                   party = c("dem","other", "rep", "dem","other", "rep", "dem","other", "rep"),
                   cond = c("current house", "current house", "current house", "midterm-only seat share prediction", "midterm-only seat share prediction", "midterm-only seat share prediction", "all-elections seat share prediction", "all-elections seat share prediction", "all-elections seat share prediction"))

plot$party <- factor(plot$party, levels=c('rep', 'other', 'dem'))
plot$cond <- factor(plot$cond, levels=c('midterm-only seat share prediction', 'all-elections seat share prediction', 'current house'))

ggplot(plot, aes(x=cond, y = seats, fill = party)) +
  geom_col(stat='identity', position = position_stack(vjust = 0.5), fill = c("dodgerblue2", "grey", "firebrick", "dodgerblue2", "grey", "firebrick", "dodgerblue2", "grey", "firebrick")) +
  geom_text(aes(label = ifelse(party == "other", "", seats)), size = 5, hjust = 4, vjust = 0, position = "stack", color = "white") +
  coord_flip() +
  labs(x = "",
       y = "seats") +
  theme_bw() +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()) +
  labs(title = "Current House Make-Up and Model Predictions")
  
  

```

In conclusion, these models seem to suggest a close race. The models that use data across all elections predict a near equal 50/50 split in both vote share and seat share, while the midterm-only models slightly favor Republicans and predict them winning the house with 202 seats. 

Throughout this class we have learned all sorts of modelling techniques and taken close looks at various independent variables to include. While it is impossible to know what will certainly happen on election day and predict exactly how everyone will vote, these forecasting methods will hopefully get us close. I look forward to reflecting on these models and methods after seeing how they performed.

```{r}

# Maine District 2 prediction ?

maine <- distdata %>%
  filter(district_id == "ME02") %>%
  distinct(year, .keep_all = TRUE) %>%
  filter(year >= 1980)
  
```




































