---
title: The Ground Game
author: Hannah Valencia
date: '2022-10-16'
slug: []
categories: []
tags: []
summary: "This week we learned about how election turnout can affect the outcome of races, and how on-the-ground campaigning efforts aim to mobilize and persuade voters. We can look at this data on the district-level to uncover patterns, and compare it to last week's data on ad spending to see how they interact."
---

*This blog is part of a series related to Gov 1347: Election Analytics, a course at [Harvard University](https://www.harvard.edu/) taught by Professor [Ryan D. Enos](http://ryandenos.com/)*.

*This week we learned about how election turnout can affect the outcome of races, and how on-the-ground campaigning efforts aim to mobilize and persuade voters. We can look at this data on the district-level to uncover patterns, and compare it to last week's data on ad spending to see how they interact.*


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# load libraries

library(tidyverse)
library(usmap)
library(plotly)
library(rmapshaper)
library(sf)
library(haven)
library(stringr)
library(sjlabelled)
library(usdata)
library(stargazer)

```


```{r}
poll <- read_csv("week3_data.csv")
generic_polls <- read_csv("GenericPolls1942_2020.csv")
house <- read_csv("house party vote share by district 1948-2020.csv")
expert_rating <- read_csv("expert_rating.csv")
house_polls_long <- read_csv("house_polls_long.csv")
ratings2018 <- read_csv("2018_ratings_share.csv")
cvap_2012_2020 <- read_csv("cvap_district_2012-2020_clean.csv")[, -c(1:2)]
dist_polls <- read_csv("dist_polls_2018-2022.csv")
fund1 <- read_csv("data1.csv")[, -c(1:2)]
econ <- read_csv("data2.csv", skip = 1)[, -1]
state_econ <- read_csv("state_df.csv")[, -1]
incumb_dist <- read_csv("incumb_dist_1948-2020 (3).csv")[, -c(1:2)]
```

```{r}

# FIXING DATA FROM OTHER WEEKS TO ADD TO MASTER

# mutating the state-level economic variables to get a Q3 mean unemployment rate for each state from 2014-2021

state_econ1 <- state_econ %>%
  filter(Year >= 2014,
         Month %in% c(7:9)) %>%
  select(`FIPS Code`, `State and area`, Month, Year, Unemployed_prct) %>%
  group_by(`State and area`, Year) %>%
  pivot_wider(names_from = Month, values_from = Unemployed_prct) %>%
  mutate(Q3_unemployed = sum(`7`, `8`, `9`)/3)


# mutating the national economic data for House incumbent and House winner from 2014-2020

econ1 <- econ %>%
  filter(year >= 2014) %>%
  select(year, winner_party, H_incumbent_party) %>%
  rename(H_winner_party = winner_party)


# mutating the pollster expert ratings at the district level for average poll rankings on the 1-7 scale

expert_rating1 <- expert_rating %>%
  filter(year >= 2014) %>%
  select(year, state, district, cook, rothenberg, sabatos_crystal_ball) %>%
  group_by(year, state, district) %>%
  mutate(avg_rating = sum(cook, rothenberg, sabatos_crystal_ball)/3) %>%
  select(year, state, district, avg_rating)

# formatting the district to match the master df
expert_rating1$district[expert_rating1$district == "AL"] <- "00"
expert_rating1$district[expert_rating1$district == "1"] <- "01"
expert_rating1$district[expert_rating1$district == "2"] <- "02"
expert_rating1$district[expert_rating1$district == "3"] <- "03"
expert_rating1$district[expert_rating1$district == "4"] <- "04"
expert_rating1$district[expert_rating1$district == "5"] <- "05"
expert_rating1$district[expert_rating1$district == "6"] <- "06"
expert_rating1$district[expert_rating1$district == "7"] <- "07"
expert_rating1$district[expert_rating1$district == "8"] <- "08"
expert_rating1$district[expert_rating1$district == "9"] <- "09"

# adding 2018 ratings

ratings2018_1 <- ratings2018 %>%
  select(District, avg) %>%
  separate(District, c("state_abb", "district"), "-")

# changing the state from abbreviations to names
ratings2018_1$state <- state.name[match(ratings2018_1$state_abb, state.abb)]
ratings2018_1$year <- 2018

ratings2018_1 <- ratings2018_1 %>%
  select(year, state, district, avg) %>%
  rename(avg_rating_2018 = avg)


# mutating generic ballot data - want only polls conducted in the 30 days until the election -> average those polls
# gives us the average support for the party in the month leading up to the election

gp1 <- generic_polls %>%
  filter(year >= 2014,
         days_until_election <= 31) %>%
  select(pollster, dem, rep, year) %>%
  group_by(year) %>%
  mutate(gen_avg_dem = mean(dem),
         gen_avg_rep = mean(rep)) %>%
  select(year, gen_avg_dem, gen_avg_rep)

# fix the CVAP data to match format of master df
cvap_1 <- cvap_2012_2020 %>%
  filter(year >= 2014) %>%
  select(year, geoid, cvap, moe)

```


```{r}

# CREATING MASTER DF

# creating a master df for district-level modeling, starting with the incumb_dist df as a base
# will only use 2014 to present for model (for now)

data <- incumb_dist %>%
  filter(year >= 2014)

# adding relevant variables from other dfs we have seen over the weeks to the master df

data <- left_join(data, state_econ1, by = c("state" = "State and area", "year" = "Year"))
data <- left_join(data, econ1, by = c("year" = "year"))
data <- left_join(data, expert_rating1, by = c("year" = "year", "state" = "state", "district_num" = "district"))
data <- left_join(data, ratings2018_1, by = c("year" = "year", "state" = "state", "district_num" = "district"))
data <- left_join(data, gp1, by = c("year" = "year"))
data <- left_join(data, cvap_1, by = c("year" = "year", "st_cd_fips" = "geoid"))

# adding a variable for if the district is solid D/R in the form of a yes/no variable
# adding a variable for turnout: coded as the sum of Rep/Dem Votes dividied by CVAP - limitation: this does not account for third party voters
data <- data %>%
  mutate(party_solid = ifelse((avg_rating >= 6 | avg_rating <= 2 | avg_rating_2018 >= 6 | avg_rating_2018 <= 2), "Yes", NA),
         dist_turnout = ((RepVotes + DemVotes)/cvap))

# creating two new dataframes: one for if the district is solid D or R, and another for districts that are not solid D/R
# coded solid as a score if either of the average ratings columns are greater than or equal to 6 (solid R) or less than or equal to 2 (solid D)

solid_dist_data <- data %>%
  filter(party_solid == "Yes") %>%
  select(!c(`7`, `8`, `9`))

battle_dist_data <- data %>%
  filter(is.na(party_solid)) %>%
  select(!c(`7`, `8`, `9`))

```

So far, we have compiled data on election outcomes, generic ballot polls, expert district-level polls, advertising campaigns, and more. When thinking about elections, however, one of the first things that may come to mind are the on-the-ground campaigns. This week we add this "Ground Game" data to our models, specifically with voter turnout at the district level. 

For starters, below we have a basic regression of a district's turnout percentage on the Democratic party's major vote percentage in a district. The turnout percentage is coded as the sum of Democratic votes and Republican votes, divided by the district's citizen voting age population (CVAP). The regression below looks at data from 2014 to 2020, including both presidential and midterm years.

```{r}
x <- data %>%
  distinct(year, st_cd_fips, DemVotesMajorPercent, dist_turnout)

fit1 <- lm(data = x, DemVotesMajorPercent ~ dist_turnout)
summary(fit1)

```

In this regression, we can see that the intercept is 54.63 percent major vote share for Democrats, representing that when voter turnout is zero, we estimate an average Democratic major vote percentage of 54.63%. When voter turnout is 100%, the Democratic major vote percentage decreases by 5.99 percentage points, to 48.64%. While we do not expect a turnout of 0%, and can only one day hope for a voter turnout of 100%, this model shows us the overall relationship between party vote share and voter turnout. While it is common to think that high voter turnout would benefit Democrats, as they often stress the importance of voting more so than the Republican party, this regression model suggests that higher voter turnout actually *hurts* Democrats. It is worth noting, however, that the R-squared for this model is extremely low, at only 0.0015, essentially stating that there is no relationship between the values of turnout that affect the democratic two party vote percentage. The coefficient on turnout is also not statistically significant, so we don't take much away from this model in terms of prediction power.

Now adding to this model, we incorporate whether or not the winning candidate in the district was an incumbent. It is thought that incumbents likely have an edge in an election, especially with house elections where often many people don't even know who their representative is -- it is just easier to vote for the incumbent if there are no real district-level issues. However, if people are unhappy with the government in some capacity at any level, then being an incumbent may be harmful: people just want change, even if the representative did nothing wrong. By regressing the candidate incumbency on the two party vote percentage for both Democrats and Republicans, we can see if there is a relationship between incumbency and vote share and whether it really is positive like we expect it to be. For this regression, incumbency is coded as 1 for an incumbent and 0 for a challenger. Again this model looks at the election years from 2014 to 2020. I will run it for both Republican vote share and Democratic vote share to see if there is a difference between parties.

```{r}

# add incumbency

data <- data %>%
  mutate(cand_incumbent = case_when(DemStatus == "Incumbent" ~ 1,
                                    DemStatus == "Challenger" ~ 0,
                                    RepStatus == "Incumbent" ~ 1,
                                    RepStatus == "Challenger" ~ 0))

x2 <- data %>%
  distinct(year, st_cd_fips, cand_incumbent, DemVotesMajorPercent, RepVotesMajorPercent, dist_turnout)
  
fit2 <- lm(data = x2, DemVotesMajorPercent ~  cand_incumbent)
summary(fit2)

fit3 <- lm(data = x2, RepVotesMajorPercent ~  cand_incumbent)
summary(fit3)

```

For the Democratic regression, when the candidate is a challenger, they have a predicted democrat two-party vote percentage of 39.64%. When the candidate is an incumbent, however, the vote percentage increases by 25.8 percentage points, to a Democratic vote percentage of 65.44%. The coefficient here is also highly significant, showing us that the relationship between a candidate's status as an incumbent and their democratic vote share is highly correlated. I also ran this regression on Republican vote percentage and found a different outcome. Here, the model shows that when a candidate is a challenger, they receive 60.36% of the two-party vote share. The coefficient on candidate incumbency in this model is highly negative, with a coefficient of -25.80, and highly significant. For the Republican two-party vote share, when a candidate is an incumbent, it actually *hurts* their votes. These results seem a bit strange to me, especially in their magnitude of difference. Not only would I expect incumbency to have the same sign on the coefficient for both Republicans and Democrats, but I also did not expect the coefficient to be so large and significant. The adjusted r-squared of this model is 0.2992, showing that while not necessarily a *good* predictor of two-party vote share, the candidate's incumbency does have a somewhat notable relationship with the vote percentage.

I would like to see how both incumbency and voter turnout influence vote share by adding the variables to the same regression.

```{r}
fit4 <- lm(data = x2, DemVotesMajorPercent ~  dist_turnout + cand_incumbent)
summary(fit4)
```

Similar to the two separate regressions we saw before, in this model incumbency is again highly significant and of a large magnitude, while turnout is small and insignificant. The adjusted r-squared of this regression is 0.2995, which is pretty much the same as what we saw in the model that used only incumbency as an independent variable. Adding turnout does very little to adjust this model.

For the final part of this extension, I will also add the expert ratings to the model. This will hopefully have a large impact on the predicted vote percentage, as we saw these ratings to be a good indicator of vote share in earlier blogs. This expert rating is the generic ballot average for the year, as that data is national. I will use only the generic ballot support data for the democratic party, given that the dependent variable I am using is Democratic two-party vote percentage.

```{r}
x3 <- data %>%
  select(year, st_cd_fips, DemVotesMajorPercent, RepVotesMajorPercent, dist_turnout, cand_incumbent, gen_avg_dem) %>%
  distinct(year, st_cd_fips, cand_incumbent, DemVotesMajorPercent, RepVotesMajorPercent, dist_turnout, gen_avg_dem)

fit5 <- lm(data = x3, DemVotesMajorPercent ~  dist_turnout + cand_incumbent + gen_avg_dem)
summary(fit5)

```

Oh no... Looking at this we can immediately see that the intercept is negative, which as we spent a long time discussing this past week, is not possible! The democratic two-party vote share percentage only exists in the 0-100% range -- it cannot be a negative value. And on top of that, the district's turnout is a negative number as well with a high magnitude relative to the intercept coefficient. Something is seriously wrong here.



```{r}

# code from section

cvap_district <- cvap_2012_2020 %>%
  rename(st_cd_fips = geoid) 

# merge with district-level polls
polls_df <- house_polls_long %>%
  filter(year == '2018' | year == '2020')
table(polls_df$year)
# join
cvap_district <- cvap_district %>%
  # filter to relevant years 
  filter(year == '2018' | year == '2020')

polls_cvap_df <- merge(polls_df, cvap_district, by = c('st_cd_fips', 'year'))

# merge with district-level voteshares
dist_pv_df <- incumb_dist
dist_pv_df <- dist_pv_df %>%
  filter(year == '2018' | year == '2020')

polls_cvap_vp_df <- merge(polls_cvap_df, dist_pv_df, by = c('st_cd_fips', 'year'))
table(polls_cvap_vp_df$st_cd_fips)

```




















