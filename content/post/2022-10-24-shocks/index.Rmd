---
title: Shocks
author: Hannah Valencia
date: '2022-10-24'
slug: []
categories: []
tags: []
summary: "This week we learned about how the things we cannot predict happening can end up affecting election outcomes. Shocks capture everything from natural disasters and Supreme Court decisions to e-mail scandals and sports outcomes. While no one expects these events to happen, voters sometimes blame candidate losses on these shocks. We will look to explore the true effect of these political shocks, or lack thereof, on elections."
---

*This blog is part of a series related to Gov 1347: Election Analytics, a course at [Harvard University](https://www.harvard.edu/) taught by Professor [Ryan D. Enos](http://ryandenos.com/)*.

*This week we learned about how the things we cannot predict happening can end up affecting election outcomes. Shocks capture everything from natural disasters and Supreme Court decisions to e-mail scandals and sports outcomes. While no one expects these events to happen, voters sometimes blame candidate losses on these shocks. We will look to explore the true effect of these political shocks, or lack thereof, on elections.*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# load libraries

library(tidyverse)
library(usmap)
library(plotly)
library(rmapshaper)
library(sf)
library(haven)
library(stringr)
library(sjlabelled)
library(usdata)
library(stargazer)

```


During an election year, there are always unexpected stories to come out about candidates, business cycle swings, or other shocks that can influence voters at the polls. Incumbents can pay the price when things in the world are going wrong, like sports teams losing or rainy weather, regardless of whether or not they have anything to do with it. For example, [Achen and Bartels](https://muse-jhu-edu.ezp-prod1.hul.harvard.edu/book/64646) concluded that shark attacks in New Jersey reduced Woodrow Wilson's vote share by ten percentage points. While [Fowler and Hall](https://hollis.harvard.edu/primo-explore/fulldisplay?docid=TN_cdi_crossref_primary_10_1086_699244&context=PC&vid=HVD2&search_scope=everything&tab=everything&lang=en_US) contest this finding, the impact of shocks on politics is a continuing debate.

The effects of these shocks on candidate support may bear more meaning during a national election, but they may also affect sentiments toward each party in terms of a generic ballot. We know from previous analyses that the generic ballot is a decent predictor for House elections, so exploring how shocks influence house elections with the thought of possibly accounting for them in our predictive models is a reasonable inquiry.

There have been several shocks so far in 2022, some very political, such as the Dobbs Supreme Court decision on abortion, historic levels of inflation, a student-loan forgiveness plan introduction, and more. In class we saw how the Dobbs decision was covered in the news and how it affected party sentiments, with Republican support declining and Democratic support increasing in the aftermath. In an extension on this, I want to see how the economic shocks we experienced in the US this past summer influenced party support. On July 13th, the Bureau of Labor Statistics reported inflation data from June, recording a consumer price index (CPI) of 9.1% from the year prior - a figure that hadn't been seen since 1981. With a Democratic president in office, some people placed the blame of this increased cost of living on President Biden and his party.

By scraping the New York Times articles, we can see below the number of articles that used the word "inflation", with the vertical line marking the day that the BLS reported the inflation statistic to the public.

```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
library(dotenv)
library(jsonlite)
library(tidyverse)
library(lubridate)

# # load up hidden api key
# article_api <- "dVwjYGqCiI59JcmfelSCnvnR6eK5Ltzy"
# #semantic_api <- Sys.getenv("SEMANTIC_API")
# 
# # set base url
# base_url_art <- "http://api.nytimes.com/svc/search/v2/articlesearch.json?fq="
# #base_url_sem <- "http://api.nytimes.com/svc/semantic/v2/concept/name"w
# 
# # set parameters
# term <- "inflation"
# facet_field <- "day_of_week"
# facet <- "true"
# begin_date <- "20220101"
# end_date <- "20221024"
# complete_url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json?fq=inflation&facet_field=day_of_week&facet=true&begin_date=20220101&end_date=20221015&api-key=dVwjYGqCiI59JcmfelSCnvnR6eK5Ltzy"
# 
# 
# complete_url2 <-paste0(base_url_art,fq =term,"&facet_field=",facet_field,"&facet=",facet,"&begin_date=",begin_date,"&end_date=",end_date,"&api-key=",article_api,sep = "")
# 
# # import dataset to R
# sus <- fromJSON(complete_url2)
# 
# # view how many hits
# sus$response$meta$hits
# 
# hits <- sus$response$meta$hits
# cat("There were ",hits," hits for the search term Inflation during 2022 to date",sep = "")
# 
# max_pages <- round((hits / 10) - 1)
# 
# pages <- list()
# Sys.sleep(1)
# for(i in 0:24){
#   mydata <- fromJSON(paste0(complete_url2, "&page=", i))
#   message("Retrieving page ", i)
#   pages[[i+1]] <- mydata$response$docs
#   Sys.sleep(6)
# }
# 
# #combine all into one
# organizations <- rbind_pages(pages)
# 
# #check output
# nrow(organizations)
# 
# colnames(organizations)
# 
# 
# # trying with hits
# sus0 <- fromJSON(paste0(complete_url2, "&page=0"), flatten = TRUE)
# nrow(sus0$response)
# sus1 <- fromJSON(paste0(complete_url2, "&page=1"), flatten = TRUE)
# nrow(sus1$response$docs)
# sus2 <- fromJSON(paste0(complete_url2, "&page=2"), flatten = TRUE)
# nrow(sus2$response$docs)
# 
# 
# #combine all into one
# mydata <- rbind_pages(pages)
# 
# #check output
# nrow(mydata)
# 
# # save df
# saveRDS(mydata, file = "inflation_2022.RDS")

# reload
mydata <- readRDS("inflation_2022.RDS")

# check colnames
# colnames(mydata)

# visualization by month
library(dplyr)
month <- mydata %>% 
  group_by(month = month(pub_date, label = T)) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(month, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "",
         title = "NYT Articles mentioning Inflation in 2022",
         color = "")

# visualization by day
day <- mydata %>% 
  group_by(month_day = paste0(month(pub_date, label = T),
           day = day(pub_date))) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(month_day, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "",
         title = "NYT Articles mentioning Inflation in 2022",
         color = "")

# how about visualization by week
# extract raw date
mydata <- mydata %>% 
  mutate(publ_date = substr(pub_date, 1, 10))

# mutate week variable
mydata <- mydata %>% 
  mutate(week = strftime(publ_date, format = "%V"))

# plot
week <- mydata %>% 
  group_by(week) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(week, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "Week",
         title = "NYT Articles mentioning Inflation in 2022",
         color = "") + # now add line for when decision was leaked
      geom_segment(x=("28"), xend=("28"),y=0,yend=37, lty=2, color="purple", alpha=0.4) +
      annotate("text", x=("18"), y=35, label="Highest Inflation Released", size=3)

```

```{r, eval=TRUE, echo=FALSE}
# plot
mydata %>% 
  group_by(week) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(week, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "Week",
         title = "NYT Articles mentioning Inflation in 2022",
         color = "") + # now add line for when decision was leaked
      geom_segment(x=("28"), xend=("28"),y=0,yend=37, lty=2, color="purple", alpha=0.4) +
      annotate("text", x=("22"), y=35, label="Highest Inflation Released", size=3) +
      geom_segment(x=("30"), xend=("30"),y=0,yend=37, lty=2, color="red", alpha=0.4) +
      annotate("text", x=("33"), y=35, label="Fed Rate Hike", size=3) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

We can see a spike in the number of articles on that day, but we also see other spikes falling at regular intervals earlier in the year as well - weeks 8, 14, and 20. After some further investigation, it seems that these were also around the times when the BLS released the prior month's CPI. The spike of articles during the week of July 13th, when the high inflation was first reported, is not that much higher than in the year's prior spikes, we see another spike almost immediately following, in week 30, or July 24th-30th. This was the week when the Fed announced their interest rate hike that was to curb inflation. In analyzing the frequency of the word "inflation" in articles, we not only capture the shock of the summer's high CPI, but also the shock of the Fed's decision.

Now in looking at how both of these impacted party sentiments: below we mark these dates on a graph of the generic ballot over time. 

```{r}

library(plyr)

X538_generic_ballot_averages_2018_2022 <- read_csv("538_generic_ballot_averages_2018-2022.csv")
gb <- X538_generic_ballot_averages_2018_2022

# convert dat
gb <- gb %>%
  mutate(date_ = mdy(date)) %>%
  mutate(year = substr(date_, 1, 4)) %>%
  filter(year == 2022) %>%
  mutate(week = strftime(date_, format = "%V")) # Jan 1 looks weird 

 #get avg by party and week
 dem <- gb %>%
   filter(candidate == 'Democrats')
 x <- plyr::ddply(dem, .(week), function(z) mean(z$pct_estimate))
 x$candidate <- c('Democrats')
 x$avg_dem <- x$V1
 x <- x %>%
   select(-V1)
 x$avg_dem <-  round(x$avg_dem , digits = 1)


 rep <- gb %>%
   filter(candidate == 'Republicans')
 y <- plyr::ddply(rep, .(week), function(z) mean(z$pct_estimate))
 y$candidate <- c('Republicans')
 y$avg_rep <- y$V1
 y <- y %>%
   select(-V1)
 y$avg_rep <-  round(y$avg_rep, digits = 1)

 #put all data frames into list
 df_list <- list(gb, x, y)

 #merge all data frames together
 polls_df <- df_list %>% reduce(full_join, by=c("candidate", "week"))

 # remove NAs
 polls_df[] <-  t(apply(polls_df, 1, function(x) c(x[!is.na(x)], x[is.na(x)])))

 polls_df <- polls_df %>%
   select(-avg_rep)

 polls_df$avg_support <- polls_df$avg_dem

 polls_df <- polls_df %>%
  select(-avg_dem)

 # keep only unique dates
 polls_df <- polls_df %>%
   distinct(cycle, week, date_, avg_support, candidate) %>%
   filter(week != 52)

 #visualize polls
 polls_df %>%
   #group_by(candidate == 'Democrats') %>%
   #mutate(date_ = as.Date(date_)) %>%
   ggplot(aes(x = week, y = avg_support,
              colour = candidate)) +
   geom_line(aes(group=candidate), size = 0.3) + geom_point(size = 0.3) +
     #scale_x_date(date_labels = "%b, %Y") +
   ylab("generic ballot support") + xlab("") +
     theme_classic() +
   # now add line for when decision was leaked and released
    geom_segment(x=("28"), xend=("28"),y=0,yend=33, lty=2, color="purple", alpha=0.4) +
    annotate("text", x=("22"), y=31, label="Highest Inflation Released", size=3) +
    geom_segment(x=("30"), xend=("30"),y=0,yend=33, lty=2, color="red", alpha=0.4) +
    annotate("text", x=("33"), y=31, label="Fed Rate Hike", size=3) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


```

We can see that when the report of inflation reaching 9.1% in June was released, The Republican party support was already on a decline and continued to decline further. We also see the exact opposite with the Democratic party, where support was already on the rise and it continued to rise. This is slightly counter-intuitive to the effect we would have expected to see with a shock of this nature. Given that the government at the time of this inflationary period is controlled by Democrats, we would have expected to see support for Democrats to decrease after this news, but we see the exact opposite. When the Federal Reserve hiked the interest rates in late July, we see the same trend of decreasing Republican support - but with a short plateau period immediately following this news break. However, we also see Democratic support fall a week after this too. While this graph can be picked apart and inferences can be made about how these shocks impacted party support, it seems that these trends are the result of larger forces. There are many shocks that took place over the course of this year that may have impacted the generic ballot, or there may just be generally changing sentiments about the parties throughout the country that have no rhyme or reason and lead to these fluctuations. It is also worth noting that the y-axis range is around 4 percentage points, meaning these fluctuations are not nearly as large as the graph may make them appear.

From this analysis in addition to class to class discussion, it does not seem like we can accurately measure the effect of a single shock on party sentiments or election predictions. There will always be shocks and they occur frequently, but their effect is temporary. News outlets may place blame on a shock for the outcome of an election to stir up a story, but it is impossible to determine whether or not a shock cost a candidate an election.


### Model

Over the past few weeks, we have tested out adding different pieces of election data to our models to see if they will yield more significant results and improve our predictions for this year's election. Some of these attempts showed real predictive power, like the generic ballot and real disposable income changes, while some of the data fell short of what we had hoped, such as that on advertising. In adjusting my model this week, I will stick to the fundamentals of incumbency, economic variables, and turnout to see if my model has improved. I will try new combinations of variables, weights, and methods to hopefully improve upon this model.

Throughout my models in previous weeks, I have found a few variables to be consistently significant and therefore will keep them in my model. Similar to in previous weeks, Democratic vote share will be the dependent variable of the model. We will also use democratic vote share from the previous election as an independent variable, along with unemployment rate in Quarter 7, the President's party, the House's majority party, the generic ballot, and voter turnout.

```{r}

# load in master data frames created in Week 6: Ground Game

data <- read.csv("data.csv")
fulldata <- read.csv("fulldata.csv")


```

```{r}

# creating a lagged vote percentage variable to create a variable for vote percentage from the prior election

df1 <- fulldata %>%
  select(year, st_cd_fips, DemVotesMajorPercent) %>%
  distinct(year, st_cd_fips, .keep_all = TRUE) %>%
  mutate(year = year + 2,
         lag_DemVS = DemVotesMajorPercent) %>%
  select(!DemVotesMajorPercent)

fulldata <- left_join(fulldata, df1, by = c("year" = "year", "st_cd_fips" = "st_cd_fips"))

# creating a variable for whether the seat was previously occupied by a democrat or republican (incumbent party by district)

fulldata <- fulldata %>%
  mutate(inc_party = ifelse(winner_party == "R" & winner_candidate_inc == "Incumbent", "R", "D"))
  

```

```{r, results = 'asis', message=FALSE, warning = FALSE}

fit1 <- lm(data = fulldata, DemVotesMajorPercent ~ gen_avg_dem)
#summary(fit1)

fit2 <- lm(data = fulldata, DemVotesMajorPercent ~ gen_avg_dem + inc_party)
#summary(fit2)

fit2 <- lm(data = fulldata, DemVotesMajorPercent ~ gen_avg_dem + inc_party + president_party)
#summary(fit2)

fit3 <- lm(data = fulldata, DemVotesMajorPercent ~ gen_avg_dem + inc_party + president_party + dist_turnout)
#summary(fit3)

fit4 <- lm(data = fulldata, DemVotesMajorPercent ~ gen_avg_dem + inc_party + president_party + dist_turnout + lag_DemVS)
#summary(fit4)

fit5 <- lm(data = fulldata, DemVotesMajorPercent ~  gen_avg_dem + inc_party + president_party + dist_turnout + lag_DemVS + Q3_unemployed)
#summary(fit5)

fit6 <- lm(data = fulldata, DemVotesMajorPercent ~  gen_avg_dem + inc_party + president_party + dist_turnout + lag_DemVS + Q3_unemployed + H_incumbent_party)
#summary(fit6)

stargazer(fit1, fit2, fit3, fit4, fit5, fit6, type = "html")

```

Looking at the R-squared and adjusted R-squared values of each of these models, we see that they increases when we add the lag of Democratic vote share in Model 4, however in Models 5 and 6 that follow both add variables that barely have any affect on the R-squared, raising it only by 0.001. These variables are unemployment in Q3 before an election, and whether the house was controlled by a democrat or a republican majority. While these two variables do not have much impact on the R-squares, they are shown in the model as being statistically significant at the highest level.

To test for multicollinearity between these independent variables, I have created the correlation plot below.

```{r}
library(corrplot)
corrplotdata <- fulldata %>% 
  select(lag_DemVS, inc_party, president_party, Q3_unemployed, gen_avg_dem, H_incumbent_party, dist_turnout) %>% 
  mutate(inc_party = ifelse(inc_party == "R", 0, 1),
         president_party = ifelse(president_party == "R", 0, 1),
         H_incumbent_party = ifelse(H_incumbent_party == "R", 0, 1)) %>%
  drop_na()

res <- cor(corrplotdata)
corrplot(res, type = "upper", order = "hclust", method = "number",
         tl.col = "black", tl.srt = 45, addCoef.col = "grey70")
```

We can see that, for the most part, the variables have very low correlation with one another. We do see a high correlation of 0.74 between the President's party and the Q3 unemployment rate, and a correlation of 0.72 between the president's party and the house incumbent party. In both of these highly correlated relationships, it is hard to believe that there are unaccounted for variables that explain this phenomenon. For example, while presidents can have some impact on the economic climate, their party is wholly uncorrelated with the business cycle swings that are a strong determinant of unemployment rates. Looking at the second relationship, we learned in class that there exists a phenomenon where the house majority party will switch at the midterm after the president party switches, therefore they may exist a linear relationship between these two variables. As I discussed earlier, the variables of the House's incumbent party and the Q3 unemployment do not improve the predictive power of the model, so to eliminate this multicollinearity, we can shift to only looking at Model 4.

We also see a somewhat high correlation between the lag of democratic vote share in the district and the seat's incumbent party. It makes sense that a relationship exists between these two because they are both looking at the outcome of the previous election cycle. If the district's incumbent was a democrat, we can expect that the district would also have a higher democratic vote share. Adding the lag democratic vote share variable did increase the R-squared value by a decent amount, as did the seat's incumbent party. In future weeks I will look into this relationship further to determine if one of these variables should be eliminated from the model.












