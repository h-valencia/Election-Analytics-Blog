---
title: Polling by District
author: Hannah Valencia
date: '2022-09-29'
slug: []
categories: []
tags: []
summary: "This week we looked at the effect of incumbency on models' predictions. We compared and contrasted various pollsters and models to see which generated the most accurate predictions, which I will continue to look at through visualizations in this blog." 
---

*This blog is part of a series related to Gov 1347: Election Analytics, a course at [Harvard University](https://www.harvard.edu/) taught by Professor [Ryan D. Enos](http://ryandenos.com/)*.

This week we looked at the effect of incumbency on models' predictions. We compared and contrasted various pollsters and models to see which generated the most accurate predictions, which I will continue to look at through visualizations in this blog.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# load libraries

library(tidyverse)
library(usmap)
library(plotly)
library(rmapshaper)
library(sf)
```

```{r, message=FALSE, warning=FALSE}

# load data

incumb_dist <- read_csv("incumb_dist_1948-2022 (2).csv")
HVS_district <- read_csv("house party vote share by district 1948-2020.csv")
expert_rating <- read_csv("expert_rating.csv")
dist_polls <- read_csv("dist_polls_2018-2022.csv")
ratings_share <- read_csv("2018_ratings_share.csv")

cd114 <- st_read("districts114.shp", quiet = TRUE)
```

```{r}

# clean data
# get labels to match shape file

HVS_district <- HVS_district %>%
  filter(raceYear == 2018) %>%
  select(raceYear, State, state_abb, district_num, RepVotesMajorPercent, DemVotesMajorPercent) %>%
  group_by(district_num, State) %>%
  mutate(DISTRICT = district_num,
         STATENAME = State,
         vsmargin = (RepVotesMajorPercent - DemVotesMajorPercent))

# make shape file district numeric
cd114$DISTRICT <- as.numeric(cd114$DISTRICT)

# join election returns with shape files
cd114_map1 <- cd114 %>% left_join(HVS_district, by=c("DISTRICT", "STATENAME"))
cd114_map1 <- ms_simplify(cd114_map1)

```

Last week, we looked at national data from generic ballot polls which gave us a general sense of political sentiment across the nation. While this data can be a good indicator for predicting elections, this week we are using more detailed, district-specific polling that gets into the strength of voter preferences. This data I expect to be even more predictive than the generic ballot polls as it looks at voter preferences in regards to the candidates they are choosing between, rather than just their general feelings towards a party - which may not accurately represent voter actions once they get to the ballot box.

To start this analysis, I used the actual voting data from the 2018 election to create a map showing the vote share margin by district. I took the difference of republican two-party vote share minus the democrat two-party vote share percentages to get a map shaded by which states won heavily vs. were more of a toss-up. This map shows most areas in a mid-light shade of red or blue, indicating that there were not *that* many districts that were entirely uncontested. The size of the districts in the northeast can make the map hard to see, but we see most of the country had a vote share margin between -50 and 50. These margins are larger than the shading of the map may indicate, but we get a good sense of the contest between parties in looking at this map.


```{r}

# actual results
# plot US Map with each district shaded by the vote share margin from the 2018 election

ggplot() +
  geom_sf(data =cd114_map1, aes(fill = vsmargin),
          inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       limits = c(-100, 100),
                       name = "Vote Share Margin") +
  theme_void() + 
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
  labs(title = "Vote Share Margin by District for 2018",
       subtitle = "Red for Republican and blue for Democratic majorities") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

```

Now moving on to the map of predicted vote by district in 2018. While I originally made this map using the expert rating data and then again trying the district polling data set, I found that with both of these provided data sets there were only 135 recorded district polls for 2018. When I tried to print the maps using this data, they ended up very grey, indicating no observation for the district. From here, I went to the class Slack page to see if anyone had the same troubles as I, and found [Ethan Jasny's cleaned data set](https://github.com/ethanjasny/gov1347). Ethan's data set provided observations for 435 districts, allowing us to create a more complete-looking map of polling.

While using the expert ratings and district polls data, I had wanted to incorporate multiple pollsters. The district polls data set has 167 unique pollsters in the full data set across the 2018, 2020, and 2022 election cycles. The expert rating data is more limited, with 15 pollsters represented in the dataset. However, in viewing this data, many of the pollsters included have NA values for most districts in 2018. To prevent any confounding that might result from including all 15 polls in some districts and only 4 in others, I had limited the data to only include four of the pollsters: the Cook Political Report, Inside Election's Rothenberg report, Sabato's Crystal Ball, and the Real Clear Politics reports. While this work can be seen in my code hidden at the bottom of my Index.Rmd, Ethan's data followed a similar logic. The data set he created that I use below uses data from all the same pollsters, except for the Real Clear Politics report. All four of these polls are highly regarded in the world of election predictions and operate on the same scale from 1-7 with 1 being Solid Democrat and 7 being Solid Republican. The map below shows the average score across these 3 polls on the same 1-7 scale. 

Looking at the map, we see strong Democratic predictions along the west and east coasts, and scattered around some major cities in in the middle of the country. The map appears heavily red, however, as some parts of the less-populated Midwest have larger districts. Most districts across the map appear to be Solid D or Solid R, as shown by their darker hues. There are some districts that are lighter shades or white, representing a prediction of a closer election where one party only has a lean estimated vote, but as it appears here and as we know from our discussions in class, there are many districts that can be counted on going one way.

```{r}

# using Ethan's cleaned data as shared on Slack to get the polling data for all congressional districts.
# when using the section data provided, only 135 observations were available, making the map mostly grey (NAs)

# separating the state name and district into their own columns
ratings_share1 <- ratings_share %>%
  separate(District, c("stateabb", "DISTRICT"), "-")

# changing the state from abbreviations to names
ratings_share1$STATENAME <- state.name[match(ratings_share1$stateabb, state.abb)]

# matching the class of the variables to that of the cd114 shape file data
ratings_share1 <- ratings_share1 %>%
  mutate(STATENAME = as.character(STATENAME),
         DISTRICT = as.numeric(DISTRICT))

# joining the data together
cd114_map5 <- cd114 %>% left_join(ratings_share1, by=c("DISTRICT", "STATENAME"))
cd114_map5 <- ms_simplify(cd114_map5)

# plot
ggplot() +
  geom_sf(data =cd114_map5, aes(fill = avg),
          inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 4,
                       limits = c(1, 7),
                       name = "Predicted Vote") +
  theme_void() +
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +
  labs(title = "Predicted Vote by District for 2018",
       subtitle = "Average predicted vote across polls for each district in 2018 from Solid D (1) to Solid R (7)") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

```

While comparing the two maps above, we can see obvious differences in the coloring, with the poll predictions having lots of darker hues and the actual vote share map showing many mid hues. This would lead us to believe that the election was more competitive than pollsters predicted. However, in the map below we will account for the difference in scales and measure the difference between the actual vote share on the 7-point scale versus the predicted vote on the 7-point scale.

I coded the 1-7 variables off of the actual vote shares for each district. For Democratic or Republican two-party vote shares greater than 56% majority, I coded these as 1 and 7 respectively, representing Solid Democrat and Solid Republican. Vote shares between 54% and 56% for each party I thought of as being likely democrat/republican, and therefore coded them as 2 and 6. Vote shares between 52% and 54% I thought of as leans for each party, and coded them as 3 and 5. Finally, vote shares between 48% and 52% I consider to be toss-ups, coding these districts as a 4.

After transforming these variables to be on the same scale as the polling predictions, I took the difference of the actual results minus the poll predicted results. This difference is depicted on the map below, which we see as being mostly white and light colors. The white represents 0 difference between the actual and predicted levels, and the significant amounts of white on the map show us that the pollsters did a good job estimating the election. The light coloring shows the places where the actual vote was more Republican (red) or Democratic (blue) than the pollsters predcited. We do not see dark colors on the map, so even when the difference was not 0, the polls were still fairly representative of the outcome.

```{r}

# Transforming the variables for the percent vote share to align with the 1-7 D/R scale

cd114_map1a <- cd114_map1 %>%
  mutate(scaledvs = case_when(DemVotesMajorPercent >= 56 ~ 1,
                              DemVotesMajorPercent >= 54 & DemVotesMajorPercent < 56 ~ 2,
                              DemVotesMajorPercent >=52 & DemVotesMajorPercent < 54 ~ 3,
                              DemVotesMajorPercent >= 48 & DemVotesMajorPercent < 52 ~ 4,
                              RepVotesMajorPercent >= 52 & RepVotesMajorPercent < 54 ~ 5,
                              RepVotesMajorPercent >= 54 & RepVotesMajorPercent < 56 ~ 6,
                              TRUE ~ 7))

# combining the data and taking the difference between the actual and predicted

cd114_map5$scaledvs <- cd114_map1a$scaledvs[match(cd114_map5$ID, cd114_map1a$ID)]
cd114_map5$vs_diff <- (cd114_map5$scaledvs - cd114_map5$avg)

```

```{r}

# plotting the difference of the actual vote and the poll predicted vote on the 1-7 scale

ggplot() +
  geom_sf(data =cd114_map5, aes(fill = vs_diff),
          inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       limits = c(-7, 7),
                       name = "Difference in Vote (actual - predicted)") +
  theme_void() + 
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
  labs(title = "Difference Between Actual and Predicted Vote Share Margin by District for 2018",
       subtitle = "Red for more actual Republican votes than predicted, blue for more Democrat") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```









```{r, warning=FALSE, eval=FALSE}

# using the expert rating data but missing many districts

# expert_rating1 <- expert_rating %>%
#   filter(year == 2018) %>%
#   select(state, district, cook, sabatos_crystal_ball, real_clear) %>%
#   mutate(STATENAME = state,
#          DISTRICT = as.numeric(district),
#          avg_pred = ((cook + sabatos_crystal_ball + real_clear)/3))
# 
# cd114_map4 <- cd114 %>% left_join(expert_rating1, by=c("DISTRICT", "STATENAME"))
# cd114_map4 <- ms_simplify(cd114_map4)
# 
# ggplot() +
#   geom_sf(data =cd114_map4, aes(fill = avg_pred),
#           inherit.aes = FALSE, alpha = 0.9) +
#   scale_fill_gradient2(low = "blue", high = "red",
#                        limits = c(1, 7),
#                        name = "Vote Share Margin") +
#   theme_void() +
#   coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +
#   labs(title = "Predicted Vote Share Margin by District for 2018",
#        subtitle = "Average vote share margin across polls for each district in 2018") +
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank(),
#         axis.title.y=element_blank(),
#         axis.text.y=element_blank(),
#         axis.ticks.y=element_blank())

```

```{r, eval=FALSE}

## cleaning poll data to match format of actual vote share data

# dist_polls1 <- dist_polls %>%
#   filter(cycle == 2018) %>%
#   
#   # vars I think might be handy to have but do not presently need
#   # select(cycle, question_id, pollster, fte_grade, state, race_id, seat_number, party, answer, pct, cd_fips, st_fips, st_cd_fips) %>% 
#   
#   # super simple list of vars that I need
#   select(question_id, st_cd_fips, state, seat_number, party, pct) %>%
#   filter(party == c("DEM", "REP")) %>%
#   pivot_wider(names_from = party, values_from = pct) %>%
#   mutate(DISTRICT = seat_number,
#          STATENAME = state,
#          vsmargin = (REP - DEM),
#          st_cd_fips = as.numeric(st_cd_fips))
# 
# # making a for loop to average the vote share margin estimated across polls for each district
# # creating an empty row for the average
# dist_polls1$vsmargin_avg <- NA
# 
# 
# # looping by each district fips code
# for(i in 1:max(dist_polls1$st_cd_fips)){
#   x <- dist_polls1 %>% filter(st_cd_fips == i)    # filter by each district
#   vsavg <- mean(x$vsmargin)    # take the mean of the vote share margin across all the polls for the district
#   
#   dist_polls1$vsmargin_avg[dist_polls1$st_cd_fips == i] <- vsavg    # save the average VS margin to the original dataframe
# }

```

```{r, eval=FALSE}

# # keeping only the necessary information for the map
# # removing duplicate rows for each district using distinct
# 
# dist_polls1 <- dist_polls1 %>%
#   select(DISTRICT, STATENAME, vsmargin_avg) %>%
#   distinct()
# 
# # joining to map data
# 
# cd114_map2 <- cd114 %>% left_join(dist_polls1, by=c("DISTRICT", "STATENAME"))
# cd114_map2 <- ms_simplify(cd114_map2)
# 
# # poll predictions
# 
# ggplot() +
#   geom_sf(data =cd114_map2, aes(fill = vsmargin_avg),
#           inherit.aes = FALSE, alpha = 0.9) +
#   scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
#                        limits = c(-100, 100),
#                        name = "Vote Share Margin") +
#   theme_void() + 
#   coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
#   labs(title = "Predicted Vote Share Margin by District for 2018",
#        subtitle = "Average vote share margin across polls for each district in 2018") +
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank(),
#         axis.title.y=element_blank(),
#         axis.text.y=element_blank(),
#         axis.ticks.y=element_blank())

```

```{r, eval=FALSE}
# 
# cd114_map3 <- cd114_map2 
# cd114_map3$vsmargin_map1 <- cd114_map1$vsmargin[match(cd114_map3$ID, cd114_map3$ID)]
# 
# 
# cd114_map3$vsmargin_diff <- (cd114_map3$vsmargin_map1 - cd114_map3$vsmargin_avg)
  
```

```{r, eval=FALSE}

# ggplot() +
#   geom_sf(data =cd114_map3, aes(fill = vsmargin_diff),
#           inherit.aes = FALSE, alpha = 0.9) +
#   scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
#                        limits = c(-100, 100),
#                        name = "Difference in Vote Share Margins (actual - predicted)") +
#   theme_void() + 
#   coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
#   labs(title = "Difference Between Actual and Predicted Vote Share Margin by District for 2018",
#        subtitle = "Red for more actual Republican votes than predicted, blue for more Democrat") +
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank(),
#         axis.title.y=element_blank(),
#         axis.text.y=element_blank(),
#         axis.ticks.y=element_blank())

```





















