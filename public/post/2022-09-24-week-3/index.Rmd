---
title: Polling
author: Hannah Valencia
date: '2022-09-24'
slug: []
categories: []
tags: []
summary: "This week, we studied various polling methods and tried to explain the variance among pollsters. Why are polls inaccurate? In this blog, I will add polling data to the economic data we looked at last week in an attempt to improve my model and generate better predictions for the upcoming midterm election."
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(ggplot2)
library(lubridate)
library(stargazer)
library(jtools)
```
<br>
*This week, we studied various polling methods and tried to explain the variance among pollsters. Why are polls inaccurate and how can we improve upon them? In this blog, I will add polling data to the economic data we looked at last week in an attempt to improve my model and generate better predictions for the upcoming midterm election.*
<br>
```{r, message=FALSE, warning = FALSE}
popvote_df <- read_csv("polling-data/popvote_df.csv", skip = 1, col_types = cols(...1 = col_skip(), ...2 = col_skip()))
economy_df <- read_csv("polling-data/economy_df.csv", col_types = cols(...1 = col_skip(), ...2 = col_skip(), ...3 = col_skip()))
data2 <- read_csv("polling-data/data2.csv", skip = 1, col_types = cols(...1 = col_skip()))
poll_df <- read_csv("polling-data/polls_df.csv")
state_df <- read_csv("polling-data/state_df.csv", skip = 1, col_types = cols(...1 = col_skip()))
data1 <- read_csv("polling-data/data1.csv", col_types = cols(...1 = col_skip()))
fte_gen_ballot_avg_2018_2022 <- read_csv("polling-data/538_generic_ballot_averages_2018-2022.csv")
fte_generic_poll_2018 <- read_csv("polling-data/538_generic_poll_2018.csv")
fte_generic_poll_2020 <- read_csv("polling-data/538_generic_poll_2020.csv")

# transform poll date to date class
poll_df$poll_date <- mdy(poll_df$poll_date)
```

When first considering how to add this polling data to my forecasting model, I decided that I would filter the data in order to make it more representative of this year's upcoming midterm election. The polling data captures polling results from 1945 to 2020, but there are various reasons as to why I have chosen not to use all of this. In class last week, we discussed how Republicans gained power in the House in the 1990s for the first time in a long time. Going off of the assumption that these races were more competitive than races from 1945-1988, and therefore more closely resemble the election we are trying to predict, I will limit the data to only elections after 1990. I believe it is also reasonable to assume that polling methods have changed since 1945, so a more recent sample will hopefully produce better, more predictive results. In addition to filtering for more recent years, I also chose to filter for midterm years, removing the years in which there was a Presidential election. As we have discussed in class and seen in other forecasts, elections in Presidential years are fundamentally different than midterm elections: there is a different voter base, campaign techniques, etc. I think limiting the polling to midterm years will create a better prediction for this year than using all of the polling data would. While this week's focus was on polling, I will be building upon models from previous weeks that use economic and historical data in hopes that all the factors together will be able to build a more predictive model.

```{r}

# filtering polling data
# Going off of last class's discussion: In the 1990s, the Republicans gained power in the House for the first time in a long time. Going off of the assumption that these races were more competitive than races from 1945-1988, and therefore more closely resemble the election we are trying to predict, I will limit the data to only elections after 1990.
# Polling methods have also likely changed, so a more recent sample will hopefully produce better results.
# I also filter the year to be only for midterm elections. As we have discussed in class and seen in other forecasts, elections in Presidential years are fundamentally different than midterm elections. There is a different voter base, campaign techniques, etc. I think limiting the polling to midterm years will create a better prediction than including everything.
# Added a column for the president's party in the year of the election, as that may help explain support

poll1 <- poll_df %>%
  filter(year %in% c(2018, 2014, 2010, 2006, 2002, 1998, 1994, 1990)) %>%
  mutate(poll_date = as.Date(poll_date, format = '%Y-%m-%d'),
         President_party = ifelse(year %in% c(2014, 2010, 1998, 1994), "D", "R"))

poll1$H_incumbent <- popvote_df$H_incumbent_party[match(poll1$year, popvote_df$year)]
poll1$D_majorvote_pct <- popvote_df$D_majorvote_pct[match(poll1$year, popvote_df$year)]
poll1$R_majorvote_pct <- popvote_df$R_majorvote_pct[match(poll1$year, popvote_df$year)]
poll1$D_totalvote_pct <- popvote_df$D_totalvote_pct[match(poll1$year, popvote_df$year)]
poll1$R_totalvote_pct <- popvote_df$R_totalvote_pct[match(poll1$year, popvote_df$year)]

```

To start, I wanted to look at the filtered polling data to see how predictive it is. The polling data is taken from a generic ballot measured in "support" for each party, with a value for each poll's predicted Democratic and Republican support as a percentage (but the two do not add up to 100%). To understand the predictive power of this generic ballot poll on the actual election results, I created a residual-esq variable that measures the actual party support from that year's election minus the generic ballot's measure of support. I then plotted this variable against the days until the election to see if they are more predictive as the election gets closer, with the hope that people's generic party support represents how they will vote in the election. The graphs of this relationship between the residual and the days until election by party are plotted below.

```{r}

# creating a residual variable that measures the difference between the actual vote share percentage and the poll predicted support for each party
# I want to see if the polls make more accurate predictions about party support (residuals get closer to 0) when they are run closer to the election.
poll1 <- poll1 %>%
  mutate(resid = case_when(party == "D" ~ (D_majorvote_pct - support),
                           TRUE ~ (R_majorvote_pct - support)))

# These plots show how the accuracy of polls (as measured by the residual) change as the election gets closer.

poll1 %>%
  ggplot(aes(x = days_until_election, y = resid, color = party)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm") +
  facet_wrap(~party) +
  scale_color_manual(values = c("dodgerblue", "firebrick")) +
  labs(x = "Days Until Election",
       y = "Actual Party Vote Share - Generic Poll Predicted Support")
```
<br>
The two plots show a wide spread of poll results across all time periods, although we do see a slightly higher concentration of points as the election gets closer. If the polls perfectly represented the way people voted in the election (and assuming all the poll respondents voted), we would see the points along the line 45-degree line of y=x with an intercept of 0. As the line of best fit for each of these plots show, the intercept is positive for both parties, meaning the generic ballot poll predictions often underestimate the actual two-party vote share. This is expected, because both the Democratic and Republican parties often do not have the highest approval ratings and may not be loved by people, but when people go to vote, they have to choose a candidate even if they do not necessarily support the party altogether. The lines of best fit also show that while there is a slightly negative relationship between the days until the election and the residual-type variable -- showing better accuracy in predicting the vote share closer to the election -- the relationship is not very strong. As we read with Gelman and King (1993), polling is most accurate in the months before an election but respondents are not often rational or informed in their choices which is why predicting the outcome is not always accurate.

One interesting note is that on the Democrat side, the polls that were taken 600+ days out from the election are clumped around a residual of 0, showing that at that time, generic party support did fairly accurately mirror the party's vote share in the election. The time frame of these points is a little less than 2 years prior to the midterm election, meaning these measurements come right after the previous Presidential election. Party support is likely high around this time and therefore corrects for the lack of support that we see later on.

Now let's get into the model. My model from last week's blog was not a great predictor, with its R-squared being around 0.5 and contained some counter-intuitive coefficients likely due to multicollinearity. I decided to start fresh, only keeping the unemployment rate. I decided to go back to the political variables from Week 1, as well, and include president party and House incumbent party in the model for this week. The dependent variable for all of these models is the two-party vote share for Democrats.
<br>

```{r}
# poll1 %>%
#   filter(party == "D",
#          days_until_election > 0) %>%
#   mutate(dte = case_when(days_until_election > 0 & days_until_election <= 10 ~ "0-10",
#                          days_until_election > 10 & days_until_election <= 30 ~ "11-30",
#                          days_until_election > 30 & days_until_election <= 60 ~ "31-60",
#                          days_until_election > 60 & days_until_election <= 90 ~ "61-90",
#                          days_until_election > 90 & days_until_election <= 150 ~ "91-150",
#                          days_until_election > 150 & days_until_election <= 200 ~ "151-200",
#                          TRUE ~ "201+"))
```

```{r, results = 'asis'}
poll2 <- poll1 %>%
  filter(party == "D",
         days_until_election > 0)

poll2$unrate <- data2$unrate[match(poll2$year, data2$year)]

fit1 <- lm(D_majorvote_pct ~ support, data = poll2)

fit2 <- lm(D_majorvote_pct ~ President_party, data = poll2)

fit3 <- lm(D_majorvote_pct ~ support + President_party, data = poll2)

fit4 <- lm(D_majorvote_pct ~ support + President_party + H_incumbent, data = poll2)

fit5 <- lm(D_majorvote_pct ~ support + President_party + H_incumbent, data = poll2, weights = days_until_election)

fit6 <- lm(D_majorvote_pct ~ support + President_party + H_incumbent + unrate + unrate*President_party, data = poll2)

fit7 <- lm(D_majorvote_pct ~ support + President_party + H_incumbent + unrate + unrate*President_party, data = poll2, weights = days_until_election)

stargazer(fit1, fit2, fit3, fit4, fit6, fit7, type = "html", covariate.labels = c("Generic Ballot Support", "President Party - Republican", "House Incumbent - Republican", "Unemployment Rate", "President Party - R * Unemployment Rate", "Constant"))

```

I decided to start off with two univariate regressions with one using the generic ballot party support as an independent variable - to get a taste of the strength of the relationship between the polls and the two-party vote share - and the second using President party as the independent variable. The generic ballot support model had a low R-squared of 0.158, which goes along with what we saw in the plots above. The Presidential party model has a much higher R-squared of 0.535, showing that this variable alone is a fairly good predictor of the vote share.

I added variables such as the House incumbent and the unemployment rate in Quarter 7, both of which improved the model. When I added an interaction between the unemployment rate and the President party, the R-square value increased a lot. As we have discussed in class and is well-known to people who follow political and economic news, unemployment rate is a good indicator of the health of the economy, and Republicans more heavily weigh economy in their voting preferences. Therefore, I expect that an interaction between these terms would add to the Republicans' two-party vote share percentage, or in the case of this model, would have a negative coefficient.

In my final model for this week, Model 6 in the table, it includes the same variables as Model 5, however I added a weight of days until the election. As previously mentioned, as we get closer to the election, the polls become more indicative of voter preferences. Model 5 has an R-squared of 0.91 and Model 6 has an R-squared of 0.92, both of which suggest that these are very good predictors of the democratic two-party vote share in the midterm elections.

While I found this model to be a good predictor, I struggled this week trying to use it to make a prediction for the 2022 election. Specifically, I did not know how exactly to include the generic ballot support from polling into the prediction model. All of the other data I can find or source, such as President party, House incumbent, unemployment rate, and days until election. The coefficient on `support` in this model is very small, so I made my prediction by eliminating it and creating a new model with the remaining variables. The R-squared value remains very high at 0.91, so the model does not suffer from the exclusion of this variable. The new model fit is described below:

```{r}
fit8 <- lm(D_majorvote_pct ~  President_party + H_incumbent + unrate + unrate*President_party, data = poll2, weights = days_until_election)
summ(fit8)
```

Now using this new model to predict the Democrat's two-party vote share in the 2022 midterm:

```{r}
preddf <- data.frame("President_party" = "D", 
                     "unrate" = 3.7,
                     "H_incumbent" = "D") 

predict(fit8, preddf, interval = "confidence")
```

This model estimates that the Democrats will receive 48.95% of the two-party vote share. I believe this seems like a logical estimation based on predictions from professional sources like FiveThirtyEight.



